[
{
	"uri": "https://ptds.samorso.ch/syllabus/",
	"title": "Syllabus",
	"tags": [],
	"description": "",
	"content": "Syllabus Discover what this class is all about and the different requirements.\n"
},
{
	"uri": "https://ptds.samorso.ch/tutorials/r_install/",
	"title": "R/RStudio installation and setup",
	"tags": [],
	"description": "",
	"content": "1. Installing R and RStudio 1.1 Installing R We start with installing the latest version of R (4.0.2 as of August 14, 2020). R itself is similar to an engine and chassis of a car, that is a bare minimum so that you can start driving. You need to follow steps below:\n Visit https://cran.r-project.org and click on \u0026ldquo;Download R for \u0026hellip;\u0026rdquo;, where \u0026hellip; coresponds to your operating system. Depending on the operating system:  For Mac: download \u0026ldquo;R-4.0.2.pkg\u0026rdquo;, open this file, and install R For Widnows: click on \u0026ldquo;base\u0026rdquo;, download the .exe file, open it, and install R    Check yourself: Open R application. In the console you will see something as follows:\nR version 4.0.2 (2020-06-22) -- \u0026#34;Taking Off Again\u0026#34; Copyright (C) 2020 The R Foundation for Statistical Computing Platform: x86_64-w64-mingw32/x64 (64-bit) R est un logiciel libre livré sans AUCUNE GARANTIE. Vous pouvez le redistribuer sous certaines conditions. Tapez \u0026#39;license()\u0026#39; ou \u0026#39;licence()\u0026#39; pour plus de détails. R est un projet collaboratif avec de nombreux contributeurs. Tapez \u0026#39;contributors()\u0026#39; pour plus d\u0026#39;information et \u0026#39;citation()\u0026#39; pour la façon de le citer dans les publications. Tapez \u0026#39;demo()\u0026#39; pour des démonstrations, \u0026#39;help()\u0026#39; pour l\u0026#39;aide en ligne ou \u0026#39;help.start()\u0026#39; pour obtenir l\u0026#39;aide au format HTML. Tapez \u0026#39;q()\u0026#39; pour quitter R. Note: If you are a Mac user and you see similar to the following warning messages during the startup\nDuring startup - Warning messages: 1: Setting LC_CTYPE failed, using \u0026#34;C\u0026#34; 2: Setting LC_COLLATE failed, using \u0026#34;C\u0026#34; 3: Setting LC_TIME failed, using \u0026#34;C\u0026#34; 4: Setting LC_MESSAGES failed, using \u0026#34;C\u0026#34; 5: Setting LC_PAPER failed, using \u0026#34;C\u0026#34; [R.app GUI 1.50 (6126) x86_64-apple-darwin9.8.0] WARNING: You\u0026#39;re using a non-UTF8 locale, therefore only ASCII characters will work. Please read R for Mac OS X FAQ (see Help) section 9 and adjust your system preferences accordingly. [History restored from /Users/nemo/.Rapp.history] you need to follow steps below:\n Open Terminal Write or paste in: defaults write org.R-project.R force.LANG en_US.UTF-8 Close Terminal  1.2 Installing RStudio Caution: Install RStudio only once R has been installed and only in this order.\nRStudio is an integrated development environment for R. Following up our exaple of the car, RStudio is similar to additional parts, such as exterior, interior, air conditioner, etc. You can drive the vehicle withour them, but life is much simpler and pleasent if they are present.\nWe will install the free version:\n Visit https://www.rstudio.com/products/rstudio/download/#download. Click on the respective version of your operating system, this will start the downloading process. Open the file and install.  Note: To improve the quality of the code, we will limit the length of lines to 80 symbols. To display the margin in RStudio sourse editor:\n Open RStudio Go to Tools -\u0026gt; Global Options… -\u0026gt; Code -\u0026gt; Display Click on “Show margin” Set \u0026ldquo;Margin column\u0026rdquo; to 80  Check yourself: Open RStudio application. In the console you will see something as follows:\nR version 4.0.2 (2020-06-22) -- \u0026#34;Taking Off Again\u0026#34; Copyright (C) 2020 The R Foundation for Statistical Computing Platform: x86_64-w64-mingw32/x64 (64-bit) R est un logiciel libre livré sans AUCUNE GARANTIE. Vous pouvez le redistribuer sous certaines conditions. Tapez \u0026#39;license()\u0026#39; ou \u0026#39;licence()\u0026#39; pour plus de détails. R est un projet collaboratif avec de nombreux contributeurs. Tapez \u0026#39;contributors()\u0026#39; pour plus d\u0026#39;information et \u0026#39;citation()\u0026#39; pour la façon de le citer dans les publications. Tapez \u0026#39;demo()\u0026#39; pour des démonstrations, \u0026#39;help()\u0026#39; pour l\u0026#39;aide en ligne ou \u0026#39;help.start()\u0026#39; pour obtenir l\u0026#39;aide au format HTML. Tapez \u0026#39;q()\u0026#39; pour quitter R. 1.3 Installing packages Note: Packages can be installed from both R and RStudio. The installed RStudio is not required.\nIn this course we will utilize a number of packages. If a package is published on CRAN, then the procedure of installing the package is straightforward:\n Open RStudio In the console execute the following command: install.packages(\u0026quot;package_name\u0026quot;), where package_name is the name of the desired package (e.g., \u0026ldquo;ggplot2\u0026rdquo;).  Several packages, however, would have only development version (or simply be not published on CRAN). Then, knowing the GitHub link to the repo, one could follow the steps below:\n Install devtools package (if it has not yet been installed) as usual (as shown above). Type devtools::install_github(\u0026quot;username/repo\u0026quot;) and hit the Enter/return key to execute the command in the console, where username is the username of the owner of the repo, and repo is the name of the repo.  For homework you will use the following packages from CRAN: \u0026quot;tidyverse\u0026quot;, \u0026quot;rworldmap\u0026quot;, \u0026quot;rworldxtra\u0026quot;, \u0026quot;ggmap\u0026quot;, \u0026quot;devtools\u0026quot;, \u0026quot;rmarkdown\u0026quot;, \u0026quot;knitr\u0026quot;, \u0026quot;xml2\u0026quot;, \u0026quot;rvest\u0026quot;, \u0026quot;magrittr\u0026quot;, \u0026quot;shiny\u0026quot;, \u0026quot;roxygen2\u0026quot;, and \u0026quot;miniUI\u0026quot;.\nNote: Before installing the \u0026quot;devtools\u0026quot; package, you will most certainly need to install building tools. For Windows, you need to install RTools. For Mac, you need to install XCode. Check this link for more details.\nInstead of installing these packages one by one, you can pass the vector of characters packages' names:\npkgs = c(\u0026#34;tidyverse\u0026#34;, \u0026#34;rworldmap\u0026#34;, \u0026#34;rworldxtra\u0026#34;, \u0026#34;ggmap\u0026#34;, \u0026#34;devtools\u0026#34;, \u0026#34;rmarkdown\u0026#34;, \u0026#34;knitr\u0026#34;, \u0026#34;xml2\u0026#34;, \u0026#34;rvest\u0026#34;, \u0026#34;magrittr\u0026#34;, \u0026#34;shiny\u0026#34;, \u0026#34;roxygen2\u0026#34;,\u0026#34;miniUI\u0026#34;) install.packages(pkgs = pkgs) Additionally, one has to install packages from \u0026quot;ptdspkg\u0026quot; repo of SMAC-Group GitHub user, and Hadley Wickham\u0026rsquo;s \u0026quot;emo\u0026quot; package (i.e., by using devtools::install_github(\u0026quot;SMAC-Group/ptdspkg\u0026quot;) and devtools::install_github(\u0026quot;hadley/emo\u0026quot;), respectively).\nNote: Packages should be installed only once. No needs to install them every time when you want to use them (it is the same as installing Skype every time you want to call your parents). That is why it is better to do it in concole, not in source editor.\nCheck yourself: To check if a package was installed successfully, use \u0026quot;name_of_package\u0026quot; %in% rownames(installed.packages()).\n2. Installing and setting up Git, GitHub, and a Git GUI In this section we will install a distributed version-control system Git, register a new user at GitHub and connect them together.\n2.1 Installing and setting up Git  Download Git installer for Mac or for Windows. Open the downloaded file and follow the proposed steps Configure your Git to let it know who you are: git config --global user.name \u0026#34;YOUR FULL NAME\u0026#34; git config --global user.email \u0026#34;YOUR EMAIL ADDRESS\u0026#34; Please do use your UNIL email address, so that we can exploit GitHub Student Developer Pack afterwards.\n  Check yourself: Type in Terminal: git --version. It should display Git version, (e.g., git version 2.22.0)\nNote: For Mac users, Git could be already preinstalled. However, Apple does not provide the latest version, that is why we have just installed the latest Git. If the previous command shows git version 2.7.0 (Apple Git-66), we will need to change the path of the executable command git. To do so execute the following commands in Terminal:\ncd ~ touch .bash_profile echo \u0026#39;export PATH=\u0026#34;/usr/local/bin:${PATH}\u0026#34;\u0026#39; \u0026gt;\u0026gt; .bash_profile source .bash_profile Note: Sometimes RStudio has a wrong path to git command. To check it, go to Tools -\u0026gt; Global Options\u0026hellip; -\u0026gt; Git/SVN, check the box \u0026ldquo;Enable version control interface for RStudio projects\u0026rdquo;. Then, \u0026ldquo;Git executable\u0026rdquo; and which git/where git (for Mac/Windows users, respectively) should be the same. Otherwise, copy the path from Terminal to RStudio.\nTo check if it worked, type which git in Terminal and expect to see /usr/local/bin/git.\n2.2 Registering a GitHub account   Visit https://github.com and fill in the fields. Please use the same email (i.e., UNIL email) address and short username without special symbols like hyphen, periods, etc. Furthermore, use free plan.\n  Set up an SSH connection follow steps at https://help.github.com/en/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent and https://help.github.com/en/articles/adding-a-new-ssh-key-to-your-github-account\n  Set up a GitHub Student Developer Pack by visiting https://education.github.com/.\n  2.3 Installing and setting up a Git GUI  Visit https://desktop.github.com and download GitHub Desktop Install it Fill in your username and password  You can also consider GitKraken as an alternative to GitHub Desktop.\nReferences:  Happy Git and GitHub for the useR Install Git R packages  "
},
{
	"uri": "https://ptds.samorso.ch/tutorials/style/",
	"title": "R Coding Style Guide",
	"tags": [],
	"description": "",
	"content": " Good coding style is like using correct punctuation. You can manage without it, but it sure makes things easier to read. Hadley Wickham  Introduction A language is a tool that allows human beings to interact and communicate with each other. The clearer we express ourselves, the better an idea is transferred from our mind to the other. The same applies to programming languages: concise, clear and consistent codes are easier to read and/or edit. It is especially important, if you have collaborators, who depend on your code. However, even if you don\u0026rsquo;t, keep in mind that at some point in time, you might come back to your code, for example, to fix an error. And if you did not follow consistently your coding style, reviewing your code can take much longer, than you expected. In this context, taking care of your audience means to make your code as readable as possible.\nThere is no such thing as a \u0026ldquo;correct\u0026rdquo; coding style, as there is no such thing as the best color. At the end of the day, the coding style is a set of developers' preferences. If you are coding alone, sticking to your coding style and being consistent is more than enough. The story is a bit different if you are working in a team: it is crucial to agree on a convention beforehand and make sure that everyone follows it.\nEven though there is no an official style guide, R is mature and steady enough to have an \u0026ldquo;unofficial\u0026rdquo; convention. In this tutorial, you will learn these \u0026ldquo;unofficial\u0026rdquo; rules, their deviations, and most common styles.\nNaming Naming files The convention actually depends on whether you develop a file for a package, or as a part of data analysis process. There are, however, common rules:\n  File names should use .R extension.\n# Good read.R # Bad read   File names should be meaningful.\n# Good model.R # Bad Untitled1.R   File names should not contain / and spaces. Instead, a dash (-) or underscore (_) should be used.\n# Good fir_regression.R fir-regression.R # Bad fit regression.R   If the file is a part of the data analysis, then it makes sense to follow the following recommendations:\n  File names should be lowercase. There is nothing bad in having capital case names, just bear in mind UNIX systems are case insensitive, meaning that test.R and Test.R do not differ.\n# Good analyse.R # Bad Analyse.R   Use meaningful verbs for file names.\n# Good validate-vbm.R # Bad regression.R   If files should be run in a particular order, then use ascending names.\n01-read.R 02-clean.R 02-plot.R   If the file is used in a pacakge, than slightly different rules should be taken care of:\n  Mind special names:\n AllClasses.R (or AllClass.R), a file that stores all S4 classes definitions. AllGenerics.R (or AllGeneric.R), a file that stores all S4 generic functions. zzz.R, a file that contains .onLoad() and friends.    If the file contains only one function, name it by the function name.\n  Use methods- prefix for S4 class methods.\n  Naming variables   Generally, names should be as short as possible, still meaningful nouns.\n# Good fit_rt split_1 imdb_page # Bad fit_regression_tree cross_validation_split_one foo   Variable names should be typically lowercase.\n# Good event # Bad Event   NEVER separate words within the name by . (reserved for an S3 dispatch) or use CamelCase (reserved for S4 classes definitions). Instead, use an underscore (_).\n# Good event_window # Bad event.window EventWindow   DO NOT use names of existing function and variables (especially, built-in ones).\n# Bad T \u0026lt;- 10 # T is a shortcut of TRUE in R c \u0026lt;- \u0026#34;constant\u0026#34;   Naming functions Many points of naming variables are similar for naming functions:\n  Generally, function names should be verbs.\n# Good add() # Bad addition()   Use . ONLY for dispatching S3 generic.\n# Good bw_test() # Bad bw.test()   Add the underscore (_) prefix to a standard evaluation (SE) equivalent of a function (summrize vs sumarize_ ).\n  Naming S4 classes Class names should be nouns in CamelCase with initial capital case letter.\nSyntax Line length The maximum length of lines is limited to 80 characters (thanks to IBM Punch Card).\nIt is possible to display the margin in RStudio Source editor:\n Go to Tools -\u0026gt; Global Options\u0026hellip; -\u0026gt; Code -\u0026gt; Display Click on \u0026ldquo;Show margin\u0026rdquo; Set \u0026ldquo;Margin column\u0026rdquo; to 80  Spacing   Put spaces around all infix binary operators (=, +, *, ==, \u0026amp;\u0026amp;, \u0026lt;-, %*%, etc.).\n# Good x == y a \u0026lt;- a ^ 2 + 1 # Bad x==y a\u0026lt;-a^2+1   Put spaces around \u0026ldquo;=\u0026rdquo; in function calls (except for Bioconductor).\n# Good mean(x = c(1, NA, 2), na.rm = TRUE) # Bad mean(x=c(1, NA, 2), na.rm=TRUE)   Do NOT place space for subsetting ($ and @), namespace manipulation (:: and :::), and for sequence generation (:).\n# Good car$cyl dplyr::select 1:10 # Bad car $cyl dplyr:: select 1: 10   Put a space after a coma:\n# Good mtcars[, \u0026#34;cyl\u0026#34;] mtcars[1, ] mean(x = c(1, NA, 2), na.rm = TRUE) # Bad mtcars[,\u0026#34;cyl\u0026#34;] mtcars[1 ,] mean(x = c(1, NA, 2),na.rm = TRUE)   Use a space before left parentheses, except in a function call.\n# Good for (element in element_list) if (grade == 5.5) sum(1:10) # Bad for(element in element_list) if(grade == 5.5) sum (1:10)   No spacing around code in parenthesis or square brackets.\n# Good if (debug) message(\u0026#34;debug mode\u0026#34;) species[\u0026#34;tiger\u0026#34;, ] # Bad if ( debug ) message(\u0026#34;debug mode\u0026#34;) species[ \u0026#34;tiger\u0026#34; ,]   Curly braces   An opening curly brace should NEVER go on its own line and should always be followed by a new line.\n# Good if (is_used) { # do something } if (is_used) { # do something } else { # do something else } # Bad if (is_used) { # do something } if (is_used) { # do something } else { # do something else }   A closing curly brace should always go on its own line, unless it’s followed by else.\n# Good if (is_used) { # do something } else { # do something else } # Bad if (is_used) { # do something } else { # do something else }   Always indent the code inside curly braces (see next section).\n# Good if (is_used) { # do something # and then something else } # Bad if (is_used) { # do something # and then something else }   Curly braces and new lines can avoided, if a statement after if is very short.\n# Good if (is_used) return(rval)   Indentation ALWAYS indent your code!\n  No tabs or mixes of tabs and spaces.\n  There are two common number of spaces for indentation: two (Hadley and others) and four (Bioconductor). My own rule of thumb: I use four spaces indentation for data analyses scripts, and two spaces while developing packages.\n  Choose the number of spaces of indentation up-front and stick to it. Never mix different number of spaces in one project.\n  To set the number of spaces of the project, go to Tools -\u0026gt; Global options\u0026hellip; -\u0026gt; Code -\u0026gt; Editing. Check the following boxes: \u0026ldquo;Insert spaces for tab\u0026rdquo; (with \u0026ldquo;Tab width\u0026rdquo; equal to chosen number), \u0026ldquo;Auto-indent code after paste\u0026rdquo;, and \u0026ldquo;Vertically align arguments in auto-indent\u0026rdquo;.\n   Magic shortcut: Command+I (Ctrl+I for Windows/Linux) will indent a selected chunk of code. Together with Command+A (select all) it is a very powerful tool, which saves time.  Try a little exercise: paste the following code in your RStudio source editor, select it, and hit Command+I:\nfor(i in 1:10) { if(i %% 2 == 0) print(paste(i, \u0026#34;is even\u0026#34;)) } New line   Very often a function definition does not fit into one line. In this case, excessive arguments should be moved to a new line, starting from the opening parenthesis.\nlong_function_name \u0026lt;- function(arg1, arg2, arg3, arg4, long_argument_name1 = TRUE)   If arguments expand more than into two lines, than each argument should be placed on a separate line.\nlong_function_name \u0026lt;- function(long_argument_name1 = c(\u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34;), long_argument_name2 = TRUE, long_argument_name3 = NULL, long_argument_name4 = FALSE)   The same applies to a function call: excessive arguments should be indented where the closing parenthesis is located, if only two lines are sufficient.\nplot(table(rpois(100, 5)), type = \u0026#34;h\u0026#34;, col = \u0026#34;red\u0026#34;, lwd = 10, main = \u0026#34;rpois(100, lambda = 5)\u0026#34;)   Otherwise, each argument can go into a separate line, starting from a new line after the opening parenthesis.\nlist( mean = mean(x), sd = sd(x), var = var(x), min = min(x), max = max(x), median = median(x) )   If the condition in if statement expands into several lines, than each condition should end with a logical operator, NOT start with it.\n# Good if (some_very_long_name_1 == 1 \u0026amp;\u0026amp; some_very_long_name_2 == 1 || some_very_long_name_3 %in% some_very_long_name_4) # Bad if (some_very_long_name_1 == 1 \u0026amp;\u0026amp; some_very_long_name_2 == 1 || some_very_long_name_3 %in% some_very_long_name_4) I know some people who are completely against it. See the next bullet why I believe it is better.\n  If the statement, which contains operators, expands into several lines, than each line should end with an operator, not start with it. Sometimes, it makes sense to split a formula into meaningful chunks.\n# Good normal_pdf \u0026lt;- 1 / sqrt(2 * pi * d_sigma ^ 2) * exp(-(x - d_mean) ^ 2 / 2 / s ^ 2) # Bad normal_pdf \u0026lt;- 1 / sqrt(2 * pi * d_sigma ^ 2) * exp(-(x - d_mean) ^ 2 / 2 / d_sigma ^ 2) Not only it is ugly, but also syntactically wrong. In the second case, R will consider these two lines as two distinct statements: the first line will assign the value of 1 / sqrt(2 * pi * d_sigma ^ 2) to normal_pdf, and the second line will throw an error, since * does not have the first argument.\n  Each grammar statement of dplyr (after %\u0026gt;%) and ggplot2 (after +) should start from a new line.\nmtcars %\u0026gt;% filter(cyl == 4) %\u0026gt;% group_by(am) %\u0026gt;% summarize(avg_mpg = mean(mpg)) ggplot(mtcars) + geom_point(aes(x = mpg, y = qsec, color = factor(am))) + geom_line(aes(x = mpg, y = qsec, color = factor(am)))   Comments   Comment your code. Always. Your collaborators and future-you will be very grateful. Comments starts by # followed by space and actual comment.\n# This is a comment.   Comments should explain the why, not the what. Comments should not replicate the code by a plain langue, but rather explain the overall intention of the command.\n# Good # define iterator i \u0026lt;- 1 # Bad # set i to 1 i \u0026lt;- 1   Short comments can be placed after code preceded by one space, #, and then one space.\nplot(price, weight) # plot a scatter chart of price and weight   To comment/uncomment selected chunk, use Command+Shift+C.\n  Use roxygen2 comments for a package development (i.e., #') to comment functions.\n  It makes sense to split the source into logical chunks by # followed by - or =.\n# Read data #--------------------------------------------------------------------------- # Tidy data #---------------------------------------------------------------------------   Other recommendations   Use \u0026lt;- for assignment, NOT =.\n  Use library() instead of require(), unless it is a conscious choice. Package names should be characters (avoid NSE - non-standard evaluation).\n# Good library(\u0026#34;dplyr\u0026#34;) # Bad require(dplyr)   In a function call, arguments can be specified by position, by complete name, or by partial name. Never specify by partial name and never mix by position and by complete name.\n# Good mean(x, na.rm = TRUE) rnorm(10, 0.2, 0.3) # Bad mean(x, na = TRUE) rnorm(mean = 0.2, 10, 0.3)   While developing a package, specify arguments by name.\n  The required (with no default value) arguments should be first, followed by optional arguments.\n# Good raise_to_power(x, power = 2.7) # Bad raise_to_power(power = 2.7, x)   The ... argument should either be in the beginning, or in the end.\n# Good standardize(..., scale = TRUE, center = TRUE) save_chart(chart, file, width, height, ...) # Bad standardize(scale = TRUE, ..., center = TRUE) save_chart(chart, ..., file, width, height)   Good practice is to set default arguments inside the function using NULL idiom, and avoid dependence between arguments:\n# Good histogram \u0026lt;- function(x, bins = NULL) { if (is.null(bins)) bins \u0026lt;- nclass.Sturges(x) ... } # Bad histogram \u0026lt;- function(x, bins = nclass.Sturges(x)) { ... }   Always validate arguments in a function.\n  While developing a package, specify the namespace of each used function, except if it is from base package.\n  Do NOT put more than one statement (command) per line. Do NOT use semicolon as termination of the command.\n# Good x \u0026lt;- 1 x \u0026lt;- x + 1 # Bad x \u0026lt;- 1; x \u0026lt;- x + 1   Avoid using setwd(\u0026quot;/Users/irudnyts/path/that/only/I/have\u0026quot;). Almost surely your collaborators will have different paths, which makes the project not portable. Instead, use here::here() function from here() package (for details see next tutorial).\n  Avoid using rm(list = ls()). This statement delets all objects from the global enviroment, and gives you an illusion of a fresh R start (for details see next tutorial).\n  If you have read until this moment, you deserve a prize. There is a magic key combination Command+Shift+A that reformats selected code: add spaces and indent it. Do not use it exessively though!\nReferences  Advanced R Google\u0026rsquo;s R Style Guide Bioconductor Coding Style Efficient R programming Colin Gillespie’s R style guide The State of Naming Conventions in R Consistent naming conventions in R Project-oriented workflow Picture is taken from R Memes For Statistical Fiends Facebook page.  "
},
{
	"uri": "https://ptds.samorso.ch/syllabus/general/",
	"title": "General information",
	"tags": [],
	"description": "",
	"content": "Location and Time  Location: Anthropole/3174 Time: 8:30 - 12 (see the lectures schedule for more details)  Course Websites  Course website: https://ptds.samorso.ch/ Online textbook: http://r.smac-group.com/ Discussion Forum: on slack  Course Staff Instructor  Name: Samuel Orso Email: Samuel.Orso@unil.ch Office: Anthropole/3090.1 Office Hours: Appointment may be made upon request. find me on GitHub  Teaching Assistant  Name: Aleksandr Shemendyuk Email: aleksandr.shemendyuk@unil.ch Office: Extranef/107 Office Hours: Appointment may be made upon request. find me on GitHub  "
},
{
	"uri": "https://ptds.samorso.ch/homeworks/schedule/",
	"title": "Schedule",
	"tags": [],
	"description": "",
	"content": "Each homework is graded and should be finished in due time; a penalty is applied for late submission (see the syllabus).\ngantt dateFormat YYYY-MM-DD title Schedule for the homeworks section Homeworks homework 0 :active, des1, 2021-09-27, 1d homework 1 :active, des2, 2021-10-04, 2021-10-10 homework 2 :active, des3, 2021-10-11, 2021-10-24 project proposal:crit, active, des4, 2021-11-01, 6d homework 3 :active, des5, 2021-10-25, 2021-11-14 homework 4 :active, des6, 2021-11-15, 2021-11-28 section Deadlines homework 1 :crit, 2021-10-10, 1d homework 2 :crit, 2021-10-24, 1d project proposal:crit, 2021-11-07, 1d homework 3 :crit, 2021-11-14, 1d homework 4 :crit, 2021-11-28, 1d  "
},
{
	"uri": "https://ptds.samorso.ch/tutorials/workflow/",
	"title": "Project-oriented workflow",
	"tags": [],
	"description": "",
	"content": " It’s like agreeing that we will all drive on the left or the right. A hallmark of civilization is following conventions that constrain your behavior a little, in the name of public safety. Jenny Bryan  Introduction In this tutorial we will learn key aspects of making a good research project:\n reproducible portable self-contained  In data science context, reproducibility means that the whole analysis can be recreated (or repeated) from the fresh start and raw data and get exactly the same results. It means, for instance, that if the analysis involves generating random numbers, then one has to set a seed (an initial state of a random generator) to obtain the same random split each time. Ideally, everyone should also have an access to data and software to replicate your analysis (it is not always the case, since data can be private).\nPortability means that regardless the operating system or a computer, for minimal given prerequisites, the project should work. For instance, if the project uses a particular package that works only on Windows, then it is not portable. The project is also not considered as portable, if it utilizes a particular computer settings, such as absolute paths instead of relative to your project folder (e.g., when reading the data or saving plots to files). Normally, you should be able to run the code on your collaborator\u0026rsquo;s machine without changing any lines in scripts.\nWe call a project self-contained, when you have everything you need at hand (i.e., in the folder of your project) and your porject does not affect anything it did not create. The project should not use a function, which you created in the other project five years ago \u0026ndash; it is very likely that no one else has this function. Further, if you need, for instance, to save a processed data, then it should be saved separately, and not overwrite the raw data.\nWhy this is a big deal? First off, it gives more credibility to the research, because it can be verified and validated by a third party. Further, keeping the flow of analysis reproducible, portable and self-contained makes it easier to extend.\nThere are no clear boundaries between these three properties, they are very close in meaning, and often overlap. As a consequence, techniques and practice we consider further improve all of them, rather than focusing on a particular one.\nEven if it might look like a yet another git / RStudio tutorial, this is a list of my recommendations based on my own experience and various posts.\nProject folder structure The size of the project increases exponentially. A project started as a harmless code snippet can easily pile up into a huge snowball of over hundred files with unstructured folder tree. To avoid this, it is important do define the folder structure before stepping into analyses. Depending whether the project is a package or a case study, its skeleton differs significantly.\nThe folder structure of R packages is a subject to a regulation of community (CRAN and Bioconductor). It is well-defined and can be explored in R packages book, therefore, I skip it in this tutorial.\nIn contrast to R packages, there is no a single right folder structure for analysis projects. Below, I present a simple yet extensible folder structure for data analysis project, based on several references that cover this issue.\nname_of_project/ |- data | |- raw | |- processed |- figures |- reports |- results |- scripts | |- deprecated |- .gitignore |- name_of_project.Rproj |- README.md The parent folder that will contain all project\u0026rsquo;s subfolders should have the same name as your project. Pick a good one. Spending an extra 5 minutes will save you from regrets in the future. The name should be short, concise, written in lower-case, and not contain any special symbols. One can apply similar strategies as for naming packages.\nThe folder data typically contains two subfolders, namely, raw and processed. The content of raw directory is data files of any kind, such as .csv, SAS, Excel, text and database files, etc. The content of this folder is read only, so that no scripts should change the original files or create new ones. For this purpose the processed directory is used: all processed, cleaned, and tidied datasets are saved here. It is a good practice to save files in R format, rather than in .csv, since the former one is a more efficient way of storing data (both in terms of space and time of reading/writing). The preference is given to .rds files over .RData (see why in Content of R files section). Again, files should have representative names (merged_calls.rds vs dataset_1.rds). Note that it should be possible to regenerate those datasets from your scripts. In other words, if you remove all files from this folder, it must be possible to restore all of them by executing your scripts that use only the data from raw.\nThe folder figures is the place where you may store plots, diagrams and other figures. There is not much to say about it. Common extensions of such files are .eps, .png, .pdf, etc. Again, file names in the folder should be meaningful (the name img1.png does not represent anything).\nAll reports live in directory with the corresponding name reports. These reports can be of any formats, such as LaTeX, Markdown, R Markdown, Jupyter Notebooks, etc. Currently, more and more people prefer rich documents with text and executable code to LaTeX and friends.\nNot all output object of the analysis are data files. For example, you have calibrated and fitted your deep learning network to the data, which took about an hour. Of course, it would be painful to retrain the model each time you run the script, and you want to save this model. Then, it is reasonable to save it in results with .rmd extension.\nPerhaps the first by importance folder is scripts. There you keep all your R scripts and codes. That is the exact place to use prefix numbers, if files should be run in a particular order (see previous tutorial). If you have files in other scripted languages (e.g., Python), it better to locate them in this folder as well. There is also an important subfolder called depricated. Whenever you want to remove one or the other script, it is a good practice to move it to depricated at first iteration, and only then delete. The script you want to remove can contain functions or analysis used by other collaborators. Moving it firstly to depricated ensures that the file is not used by other collaborators.\nThere are three important files in the project folder: .gitignore, name_of_project.Rproj, and README.md. The file .gitignore lists files that won\u0026rsquo;t be added to Git system: LaTeX or C build artifacts, system files, very large files, or files generated for particular cases. Further, the name_of_project.Rproj contains options and meta-data of the project: encoding, the number of spaces used for indentation, whether or not to restore a workspace with launch, etc. The README.md briefly describes all high-level information about the project, like an abstract of a paper.\nThe proposed folder structure is far from being exhaustive. You might need to introduce other folders, such as paper (where .tex version of a paper lives), sources ( a place for your compiled code here, e.g. C++), references, presentations, NEWS.md, TODO.md, etc. At the same time, keeping an empty folders could be misleading, and it is better to remove them (unless you are planning to store anything in them in the future).\nSeveral R packages, namely ProjectTemplate, template, and template are dedicated to project structures. Also it is possible to construct a project tree by forking manuscriptPackage or sample-r-project repositories (repo for short). Using a package or forking a repo allow for automated structure generation, but at the same time introduce many redundant and unnecessary folders and files.\nFinally, some scientists believe that all R projects should be in a shape of a package. Indeed, one can store data in \\data, R scripts in \\R, documentation in \\man, and the paper \\vignette. The nice thing about it that anyone familiar with an R package structure can immediately grasp where each type of a file located. On the other hand, the structure of R packages is tailored to serve its purpose \u0026ndash; make a coherent tool for data scientists and not to produce a data product: there is no distinction between functions definitions and applications, no proper place for reports, and finally there are no place for other script languages that you can use (e.g, Bash, Python, etc.).\nContent of R files While there are no rules how to organize your R code, there are several dos and don\u0026rsquo;ts that most of the time are not tough explicitly. I cover them below:\n  Do not use the function install.packages() inside your scripts. You are not suppose to (re)install packages each time when you run your files. By default it is normally assumed that all packages that are used by a script are already installed.\nIf there are many of them to install, it is better to create a file configure.R, that will install all packages:\npkgs \u0026lt;- c(\u0026#34;ggplot2\u0026#34;, \u0026#34;plyr\u0026#34;) install.packages(pkgs) The snippet above profits from the fact that install.packages() is a vectorized function. Anyway, most of the time, install.packages() is suppose to be called from the console, and not from the script.\n  Do not use the function require(), unless it is a conscious choice. In contrast to library(), require() does not throw an error (only a warning) if the package is not installed.\n  Use a character representation of the package name.\n# Good library(\u0026#34;ggplot2\u0026#34;) # Bad library(ggplot2)   Load only those packages that are actually used in the script. Load packages at the beginning of the script.\n  Do not use rm(list = ls()) that erase your global environment. First, it could delete accidentally the precious heavy long-time-to-build object. Second, it gives an illusion of the fresh start of R.\n  Do not use setwd(\u0026quot;/Users/irudnyts/path/that/only/I/have\u0026quot;). It is very unlikely that someone except you will have the same path to the project. Instead, use a package here and relative paths. The package here automatically recognizes the path to the project, and starts from there:\n# Good library(\u0026#34;here\u0026#34;) cars \u0026lt;- read.csv(file = here(\u0026#34;data\u0026#34;, \u0026#34;raw\u0026#34;, \u0026#34;cars.csv\u0026#34;)) # Bad setwd(\u0026#34;/Users/irudnyts/path/that/only/I/have/data/raw\u0026#34;) cars \u0026lt;- read.csv(file = \u0026#34;cars.csv\u0026#34;)   If your script involves random generation, then set a seed by set.seed() function to get the same random split each time:\n# Good set.seed(1991) x \u0026lt;- rnorm(100) # Bad x \u0026lt;- rnorm(100)   Do not repeat yourself (DRY). In R context it means the following: if the code repeated more than to times, you had better wrap it into a function.\n# Better fix_missing \u0026lt;- function(x) { x[x == -99] \u0026lt;- NA x } df[] \u0026lt;- lapply(df, fix_missing) # Bad df$a[df$a == -99] \u0026lt;- NA df$b[df$b == -99] \u0026lt;- NA df$c[df$c == -99] \u0026lt;- NA df$d[df$d == -99] \u0026lt;- NA df$e[df$e == -99] \u0026lt;- NA df$f[df$g == -99] \u0026lt;- NA   Separate function definitions from their applications.\n  Use saveRDS() instead of save():\n    save() saves the objects and their names together in the same file; saveRDS() only saves the value of a single object (its name is dropped). load() loads the file saved by save(), and creates the objects with the saved names silently (if you happen to have objects in your current environment with the same names, these objects will be overridden); readRDS() only loads the value, and you have to assign the value to a variable. Yihui Xie    Inizializing a new data analysis project Disclaimer: the procedure below can be done in different ways. This particular way is no better than the others, but from author opinion has the most logical flow.\nPrerequisites:\n Installed and configured Git Installed R and RStudio Existing account in Github  Steps:\n  Pick a good name (e.g., beer).\n  In RStudio create a project:\n Navigate to File -\u0026gt; New project\u0026hellip; Select New Directory Select New project (unless you are developing a package or a ShinyApp) Insert your picked name into Directory name Check Create a git repository  This creates a folder with the name of the project, initialize a local git repo, generate an .Rproj file, and a .gitignore file.\n  Add a file structure as discussed in section, that is folder data (with raw and processed subfolders), figures, etc.\n  Create a README.md file.\n  Launch Terminal and navigate your working directory (of Terminal, not R) to your project folder by, for instance, cd /Users/irudnyts/Documents/projects/beer.\n  Record changes by git add --all and commit by git commit -m \u0026quot;Create a folder structure of the project.\u0026quot;. Traditionally the message of the first commit is simple \u0026quot;First commit.\u0026quot;, but I prefer to write something more conscious, like \u0026quot;Create a folder structure of the project.\u0026quot;.\nNow all you changes are recoreded locally.\nNote also that Git does not record empty folders.\n  Create a new repo in GitHub (the same procedure holds for Bitbucket and Gitlab):\n Fill in Repository name with the same name as your project. Fill in Description with one line that briefly explains the intent of the project and ends with full stop. (Check Private for homeworks). Hit Create repository.    Connect your local repo to your Github repo by\ngit remote add origin git@github.com:irudnyts/beer.git git push -u origin master Refresh the page at your browser to ensure that changes appear at Github repo (do not freak out if you do not see all folders you have created, Git does not record empty folders).\n  Working with an existing data analysis project   Pull changes introduced by your collaborators by git pull.\n  Modify your files. If you want to delete a script, first off, move it to \\depricated, and then remove it from there during the next iteration.\n  Add changes by git add --all and commit by git commit -m \u0026quot;A concious commit message.\u0026quot;.\n  Push changes by git push. Merge changes if needed.\n  References  R packages Project-oriented workflow save() vs saveRDS() Jupyter And R Markdown: Notebooks With R A sample R project structure sample-r-project repo Creating an analysis as a package and vignette Analyses as Packages Packages vs ProjectTemplate Organizing the project directory Designing projects Project Management With RStudio Folder Structure for Data Analysis Organizing files for data analysis A meaningful file structure for R projects Packaging data analytical work reproducibly using R (and friends) What\u0026rsquo;s in a Name? The Concepts and Language of Replication and Reproducibility Packaging Your Reproducible Analysis Tools for Reproducible Research Data Analysis and Visualization in R for Ecologists Stop the working directory insanity manuscriptPackage cboettig/template Pakillo/template A minimal Project Tree in R -ProjectTemplate Writing a paper with RStudio Reproducibility vs. Replicability: A Brief History of a Confused Terminology  "
},
{
	"uri": "https://ptds.samorso.ch/homeworks/hw0/",
	"title": "homework #0",
	"tags": [],
	"description": "",
	"content": "Homework generously provided by the Data Science in Business Analytics class.\nThis homework is optional and is not graded.\n In this optional tutorial you will get an overview of the basic programming concepts in R and main data types. Just enough to get you up and running essential R code. However, for true \u0026ldquo;beginners\u0026rdquo;, we highly recommend going through Advanced R - Chapter \u0026lsquo;Foundations\u0026rsquo; from which the content of this assignment is mainly (mostly) inspired by.\nInstallation and setup Please visit this page for the installation guideline.\nAssignment In R, we assign values (numbers, characters, data frames) to objects (vectors, matrices, variables). To do so, we use the \u0026lt;- operator:\n# name_of_object \u0026lt;- value an_object \u0026lt;- 2 another_object \u0026lt;- \u0026#34;some string\u0026#34; # inspect object\u0026#39;s value an_object print(another_object) Data Structures R’s base data structures can be organised by their dimensionality (1d, 2d, or nd) and whether they’re homogeneous (all contents must be of the same type) or heterogeneous (the contents can be of different types).\n    Homogeneous Heterogeneous     1d Atomic vector List   2d Matrix Data frame   nd Array     Vectors The basic data structure in R is the vector. Vectors can be of two kinds: atomic vectors and lists. They have three common properties:\n Type, typeof(), what it is. Length, length(), how many elements it contains. Attributes, attributes(), additional arbitrary metadata. They differ in the types of their elements: all elements of an atomic vector must be the same type, whereas the elements of a list can have different types.  There are four common types of atomic vectors:\n logical integer double (often called numeric) character  Atomic vectors are usually created with c(), short for combine:\ndbl_var \u0026lt;- c(1, 2.5, 4.5) # with the L suffix, you get an integer rather than a double int_var \u0026lt;- c(1L, 6L, 10L) # use TRUE and FALSE (or T and F) to create logical vectors log_var \u0026lt;- c(TRUE, FALSE, T, F) chr_var \u0026lt;- c(\u0026#34;these are\u0026#34;, \u0026#34;some strings\u0026#34;) int_var \u0026lt;- c(1L, 6L, 10L) typeof(int_var) is.integer(int_var) Lists List objects can hold elements of any type, including lists. You construct lists by using list() instead of c():\nx \u0026lt;- list(1:3, \u0026#34;a\u0026#34;, c(TRUE, FALSE, TRUE), c(2.3, 5.9)) str(x) Attributes All objects can have arbitrary additional attributes, used to store metadata about the object. Attributes can be thought of as a named list (with unique names). They can be accessed individually with attr() or all at once (as a list) with attributes().\ny \u0026lt;- 1:10 attr(y, \u0026#34;my_attribute\u0026#34;) \u0026lt;- \u0026#34;This is a vector\u0026#34; # inspect the attribute of y attr(y, \u0026#34;my_attribute\u0026#34;) Matrices and arrays Adding a dim attribute to an atomic vector allows it to behave like a multi-dimensional array. A special case of the array is the matrix, which has two dimensions. Matrices and arrays are created with matrix() and array(), or by using the assignment form of dim():\n# two scalar arguments to specify rows and columns a \u0026lt;- matrix(1:6, ncol = 3, nrow = 2) # one vector argument to describe all dimensions b \u0026lt;- array(1:12, c(2, 3, 2)) # you can also modify an object in place by setting dim() c \u0026lt;- 1:6 dim(c) \u0026lt;- c(3, 2) c length() and names() have high-dimensional generalisations:\n  length() generalises to nrow() and ncol() for matrices, and dim() for arrays.\n  names() generalises to rownames() and colnames() for matrices, and dimnames(), a list of character vectors, for arrays.\n  c() generalises to cbind() and rbind() for matrices, and to abind() (provided by the abind package) for arrays. You can transpose a matrix with t(); the generalised equivalent for arrays is aperm().\nYou can test if an object is a matrix or array using is.matrix() and is.array(), or by looking at the length of the dim(). as.matrix() and as.array() make it easy to turn an existing vector into a matrix or array.\nData frames A data frame is the most common way of storing data in R, and if used systematically makes data analysis easier. Under the hood, a data frame is a list of equal-length vectors. This makes it a 2-dimensional structure, so it shares properties of both the matrix and the list. This means that a data frame has names(), colnames(), and rownames(), although names() and colnames() are the same thing. The length() of a data frame is the length of the underlying list and so is the same as ncol(); nrow() gives the number of rows.\ndf \u0026lt;- data.frame(x = 1:3, y = c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)) str(df) You can combine data frames using cbind() and rbind():\ncbind(df, data.frame(z = 3:1)) Subsetting vectors Let’s explore the different types of subsetting with a simple vector, x.\nx \u0026lt;- c(2, 4, 3, 5) Positive integers return elements at the specified positions:\nx[c(3, 1)] Duplicated indices yield duplicated values\nx[c(1, 1)] Real numbers are silently truncated to integers\nx[c(2, 9)] Negative integers omit elements at the specified positions:\nx[-c(3, 1)] You can’t mix positive and negative integers in a single subset: x[c(-1, 2)]\nLogical vectors select elements where the corresponding logical value is TRUE. This is probably the most useful type of subsetting because you write the expression that creates the logical vector:\nx[c(TRUE, TRUE, FALSE, FALSE)] x[x \u0026gt; 3] A missing value in the index always yields a missing value in the output:\nx[c(TRUE, TRUE, NA, FALSE)] Nothing returns the original vector. This is not useful for vectors but is very useful for matrices, data frames, and arrays. It can also be useful in conjunction with assignment.\nx[] Zero returns a zero-length vector. This is not something you usually do on purpose, but it can be helpful for generating test data.\nx[0] If the vector is named, you can also use character vectors to return elements with matching names:\n(y \u0026lt;- setNames(x, letters[1:4])) y[c(\u0026#34;d\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;a\u0026#34;)] Like integer indices, you can repeat indices:\ny[c(\u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;)] Subsetting with names returns always the match exactly, if any.\nz \u0026lt;- c(abc = 1, def = 2) z[c(\u0026#34;a\u0026#34;, \u0026#34;d\u0026#34;)] Subsetting lists, matricies and data frames Subsetting a list works in the same way as subsetting an atomic vector. Using [ will always return a list; [[ and $, as described below, let you pull out the components of the list.\nYou can subset higher-dimensional structures in three ways:\n With multiple vectors. With a single vector. With a matrix.  a \u0026lt;- matrix(1:9, nrow = 3) colnames(a) \u0026lt;- c(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;) # multiple vectors a[1:2, ] df \u0026lt;- data.frame(x = 1:3, y = 3:1, z = letters[1:3]) # selecting by value of certain vector df[df$x == 2, ] Importing data in R The following checklist makes it easier to import data correctly into R:\n The first row is maybe reserved for the header, while the first column is used to identify the sampling unit; Avoid names, values or fields with blank spaces, otherwise each word will be interpreted as a separate variable, resulting in errors that are related to the number of elements per line in your data set; Short names are prefered over longer names; Try to avoid using names that contain symbols such as ? $ % ^ \u0026amp; * ( ) - # , ; . \u0026lt; \u0026gt; / | \\ { }; Make sure that any missing values in your data set are indicated with NA.  library(readr) # import data from .txt file df \u0026lt;- read_table( \u0026#34;https://s3.amazonaws.com/assets.datacamp.com/blog_assets/test.txt\u0026#34;, col_names = FALSE) df # import data from .csv file df \u0026lt;- read.table( \u0026#34;https://s3.amazonaws.com/assets.datacamp.com/blog_assets/test.csv\u0026#34;, header = TRUE, sep = \u0026#34;,\u0026#34;) Functions Standard format for defining a function in R:\nmy_function_name \u0026lt;- function(arg1 = \u0026#34;default\u0026#34;, arg2 = \u0026#34;default\u0026#34;) { # \u0026#39;cat\u0026#39; is used for concatenating strings merged_string \u0026lt;- cat(arg1, arg2) # if not specified, last evaluated object is returned return(merged_string) } # call a function elsewhere from code arg1 \u0026lt;- \u0026#34;Hello\u0026#34; arg2 \u0026lt;- \u0026#34;World!\u0026#34; a_greeting \u0026lt;- my_function_name(arg1, arg2) print(a_greeting) CRAN - the curated repository of R packages provides millions of functions that you could use to tackle data. You simply need to install a package, and then call the function from your R code function_name(somearguments). For example, the package stats helps you in fitting linear model through the function lm():\nlibrary(stats) x \u0026lt;- rnorm(500) y \u0026lt;- x*4 + rnorm(500) lm.fit \u0026lt;- lm(y~x, data = data.frame(x, y)) print(lm.fit) How many functions have been used in the example? What does rnorm mean? You can get informed about any R function by using its documentation ?function_name or ?packageName::function_name.\nTry it yourself! Exercise 1 Try to figure out the answers without executing the code. Check your answers in R Studio.\na) Given the vector: x \u0026lt;- c(\u0026quot;ww\u0026quot;, \u0026quot;ee\u0026quot;, \u0026quot;ff\u0026quot;, \u0026quot;uu\u0026quot;, \u0026quot;kk\u0026quot;), what will be the output for x[c(2,3)]?\nb) Let a \u0026lt;- c(2, 4, 6, 8) and b \u0026lt;- c(TRUE, FALSE, TRUE, FALSE), what will be the output for the R expression max(a[b])?\nc) Is it possible to apply the function my_function_name using x and a as arguments?\nExercise 2 Consider a vector x such that: x=c(1, 3, 4, 7, 11, 18, 29) Write an R statement that will return a list X2 with components of value: x * 2, x / 2, sqrt(x) and names 'x*2', 'x/2', 'sqrt(x)'.\nExercise 3 Read the file Table0.txt into an object DS.\na) What is the data type for the object DS?\nb) Change the names of the columns to Name, Age, Height, Weight and Sex.\nc) Change the row names so that they are the same as Name, and remove the variable Name.\nd) Get the number of rows and columns of the data.\nExercise 4 a) Convert DS from the previous exercise to a data frame DF.\nb) Add an additional column \u0026ldquo;zeros\u0026rdquo; in DF with all elements 0.\nc) Remove the Weight comuln from DF.\n"
},
{
	"uri": "https://ptds.samorso.ch/syllabus/coursedescr/",
	"title": "Course description",
	"tags": [],
	"description": "",
	"content": "This class is intended to introduce to the students a wide range of programming tools using the R language. Tentative list of topics that will be discussed in this class are listed below:\n Reproducible research: knitr and rmarkdown Version control: GitHub Introduction to programming: Data structures, logical operators, control structures and functions Visualizations: Exploratory data analysis with Base R and ggplot2 R packages: Construction of R-packages using devtools, roxygen2 and pkgdown Communication: webiste creation via blogdown, Web application via shiny Web scraping: Automatic extraction of data from websites using SelectorGadget, rvest and quantmod, regular expression High performance computing: R and C++ integration via Rcpp, parallel computing.  No IT background is assumed from the students but a strong will to learn useful and practical programming skills.\nThis course is complementary to the Data Science in Business Analytics class. Although not mandatory, we recommend the students to follow the Data Science in Business Analytics class prior to ours as it will facilitate they learning curve and diminish the importance of the workload that this class represents.\n "
},
{
	"uri": "https://ptds.samorso.ch/lectures/",
	"title": "Lectures",
	"tags": [],
	"description": "",
	"content": "Lectures The ideal schedule is given below. Chapters refer to the book An Introduction to Statistical Programming Methods with R\nClass-related discussion and questions will be on Slack, do not forget to register here.\nLectures fully online via Zoom are indicated with a º symbol.\n   Week Date Time Topic Instructor Videos Slides     1 27 Sept 9:00 - 10:00 Introduction, RMarkdown Samuel Orso RMarkdown, Zoom meeting Introduction, RMarkdown   1 27 Sept 10:15 - 12:00 R/RStudio installation, Homework #0, R coding style guide Aleksandr Shemendyuk     2º 4 Oct 9:00 - 10:00 GitHub, Data structures Samuel Orso GitHub, Data structures Git/GitHub, Data Structure   2 4 Oct 10:15 - 12:00 Project-oriented workflow, Homework #1 Aleksandr Shemendyuk     3º 11 Oct 9:00 - 10:00 Control structures Samuel Orso Control structures Control Structure   3 11 Oct 10:15 - 12:00 Homework #2 Aleksandr Shemendyuk     4 18 Oct 9:00 - 10:00 Functions, Group projects Samuel Orso Functions Function, Proposal   4 18 Oct 10:15 - 12:00 Homework #2 Aleksandr Shemendyuk     5º 25 Oct 9:00 - 10:00 Functions Samuel Orso Functions Function   5 25 Oct 10:15 - 12:00 Homework #3, Logistic regression Aleksandr Shemendyuk     6 1 Nov 9:00 - 10:00 Shiny Web applications Samuel Orso Shiny Shiny   6 1 Nov 10:15 - 12:00 Project proposal coaching Samuel Orso     7º 8 Nov 9:00 - 10:00 R-packaging Samuel Orso Packages R pkg   7 8 Nov 10:15 - 12:00 Homework #3 Aleksandr Shemendyuk     8º 15 Nov 9:00 - 10:00 High performance computing Samuel Orso Rcpp    8 15 Nov 10:15 - 12:00 Homework #4 Aleksandr Shemendyuk     9º 22 Nov 9:00 - 10:00 Webscraping Samuel Orso Webscraping    9 22 Nov 10:15 - 12:00 Homework #4 Aleksandr Shemendyuk     10º 29 Nov 9:00 - 10:00 blogdown: websites and blogs creation Samuel Orso     10 29 Nov 10:15 - 12:00 Extra topic Aleksandr Shemendyuk     11 6 Dec  Project coaching Samuel Orso     12 13 Dec  Project coaching      13 20 Dec  Project presentations Samuel Orso      "
},
{
	"uri": "https://ptds.samorso.ch/project/output/",
	"title": "Project",
	"tags": [],
	"description": "",
	"content": " Presentations of the projects are held the 2021-12-20. You have 15 minutes of presentation + 5 minutes of questions per group. Each member should present a piece of the presentation.\n The output of your project must be:\n An awesome project! A super R-package that can be directly installed from your GitHub repository. More specifically you should make sure:   you have a DESCRIPTION file with all necessary information including, but not limited to, Package title, general description, dependencies, license, and imports. R/Rcpp functions with documentation including title, description, parameters, authors, exports, and at least one example. A well formatted package skeleton (man, inst, docs, R, etc.) A shiny app to allow someone having absolutely no R knowledge to “use” what you have done in your project. This shiny app should be within your package. The package can seamlessly be installed from your GitHub repository (for example using remotes::install_github(\u0026quot;ptds2021/projectGX\u0026quot;) where X is your group number. A vignette that illustrates your package/shiny app with nice examples.  The GitHub repository is well-documented with nice commit messages and clear issues (close them once done!). Up-to-date GitHub projects that demonstrate your current organization for the project: TODOs, tasks in progress of resolution, tasks that have been completed. A website built using blogdown showcasing your work and your package. In particular, you should at least motivate your package and explain how to use it. You should also make a short video showing how to use the package.  "
},
{
	"uri": "https://ptds.samorso.ch/lectures/additional/",
	"title": "Supplementary material",
	"tags": [],
	"description": "",
	"content": "Try the RMarkdown Shiny app\n"
},
{
	"uri": "https://ptds.samorso.ch/tutorials/",
	"title": "Tutorials",
	"tags": [],
	"description": "",
	"content": "Tutorials This section contains the tutorials on various topics, namely, coding style guide, basics of syntax, best practice, conventions, typical workflows, etc.\n"
},
{
	"uri": "https://ptds.samorso.ch/syllabus/grading/",
	"title": "Grading",
	"tags": [],
	"description": "",
	"content": "There are 60 points in total for this class. The final grades are given as follows:\n   Grade Points     6.0 57-60   5.5 52-56   5.0 47-51   4.5 42-46   4.0 37-41   3.5 32-36   3.0 27-31   2.5 22-26   2.0 17-21   1.5 12-16   1.0 0-11    Learning outcomes will be assessed based on the performances within each of the following categories:\n   Type Points Bonus     Semester project 30 3   Homeworks 30 3    Bonuses may be obtained at our discretaion for the groups or individuals that give outstanding work for each of these categories, described in more details below.\nNo final examination for this class. The learning outcomes are continuously assessed during the semester with the homeworks, the project and the participation.\n Semester project The final project provides an opportunity to combine content learned throughout the course for use in some realistic application. All projects are conducted in groups. The details of the semester project are discussed in class and students will have the opportunity to choose between several project formats (see also the project page for more details). The 30 points of the grade are allocated according to the following criteria:\n Overall quality (3 points) Interest and complexity of the subject (3 points) Presentation (6 points) Screencast (3 points) Shiny app (3 points) Provided documentation (3 points) R package (3 points) GitHub repository (3 points) Website (3 points)  Do not underestimate the workload that the project represents. This class requires good planning and team management from the students.\n Homeworks There are four homework assignments during the semester which are realized in groups. Each of these homeworks combines some of the content learned throughout the course. There are 7.5 points per homework. Homeworks and their specific requirements are detailed at the homeworks page.\nLate submission is penalized by 1 point every 24 hours after the deadline.\n "
},
{
	"uri": "https://ptds.samorso.ch/homeworks/hw1/",
	"title": "homework #1",
	"tags": [],
	"description": "",
	"content": " Deadline: 2021-10-10 11:59pm\nTo submit your work, simply push it to the dedicated repository created for your group.\nWe will grade only the latest files prior to the deadline. Any ulterior modifications are pointless.\n The objectives of this homework assignment are the followings:\n Build your own RMarkdown document. Master different aspects of RMarkdown syntax. Become familiar with GitHub as a collaborative tool.  This homework must be accomplished using GitHub and respect the following requirements:\n All members of the group must commit at least once. All commit messages must be reasonably clear and meaningful. Your GitHub repository must include at least one issue containing some form of TO DO list.  In your repository, create a RMarkdown file called hw1.Rmd providing an HTML output with the theme cerulean and syntax highlighting tango. This file should contain the following elements:\n A \u0026ldquo;title\u0026rdquo; section which should at least include:  A title (e.g. Homework 1) The authors The date (think of using Sys.time())   A section called \u0026ldquo;Introduction\u0026rdquo; where you provide a short summary of the structure of your homework. Moreover, record a short video to introduce your group and include it in your RMarkdown document. A section called \u0026ldquo;Group Members\u0026rdquo;. This section should have one sub-section for each group member in your team. For example, a group with three members should have three sub-sections. Each of these sub-sections (named after each group member) should include small biographies containing at least the following elements:  A picture of your choice. Make sure to include a caption for this image. A paragraph describing your favorite hobby as well as one interesting fact about yourself (preferably true). Your favorite quote in blockquote format. Make sure to reference your quote using BibTex. A table having two columns (first column containing the classes you are following this semester; second column containing the time of these classes).   A section called \u0026ldquo;RMarkdown Syntax\u0026rdquo;, where you will demonstrate your RMarkdown skills! In this section make sure to:  Show an example where the chunk option cache = T leads to a misleading answer. This example must be different from the one presented in the textbook. Simulate 300 random samples from a distribution that is uniform on [-1, 1] interval using the function runif(). Store these 300 values in a vector called x. Then, compute the empirical median, mean and variance of x. Are these results different from 0, 0 and 1/3 (their respective theoretical values)? Is this result surprising? Justify your answer. Include a graph showing the density estimation of x (make sure to include a caption to this figure). You can use the R function d \u0026lt;- denstiy() with default parameters, and the plot(d) function. Why does the estimated density exceed the [-1, 1] interval? Include the following equation:  Include the following in-line equation:  Include the following text in green: \u0026ldquo;The degree of civilization in a society can be judged by entering its prisons.\u0026rdquo;, Fyodor Dostoevsky Include a \u0026ldquo;More info\u0026rdquo; button with hide/unhide functionality. Include a \u0026ldquo;color box\u0026rdquo;\u0026quot; with some text.    "
},
{
	"uri": "https://ptds.samorso.ch/project/proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": " Project proposal submission deadline is 2021-11-07 11:59pm.\n The group project is a major goal of this class (50% of the final grade). In order to make sure that your project is on the right track, you must submit a project proposal for reviewing.\nThe project proposal is a RMarkdown document (3 pages max) submitted on dedicated GitHub repository and must comprise the following sections:\n Goals and impacts: describe briefly the rationale of your project, you overall objectives and potential impacts. Plan: detail your approach and your specific objectives:   Explain the methods (R packages, \u0026hellip;) to be used and the methods to be developped. Give potential Explain existing sources of inspirations (other classes, stackoverflow, R-blogger, blogs, \u0026hellip;) and the potential overlaps with your project. Explain your data collection strategy, the risks as well as possible alternative strategies.  Timeline and milestones: describe the timeline of your project and indicate key intermediary goals in a Gantt chart (see this package for example). Management plan: explain how you plan to collaborate (weekly meeting on Zoom, \u0026hellip;) and indicate responsabilities (each member of the team should be at least responsible for one part of the project).  "
},
{
	"uri": "https://ptds.samorso.ch/homeworks/hw1-sol/",
	"title": "homework #1 solutions",
	"tags": [],
	"description": "",
	"content": "The objectives of this homework assignment are the followings:\n Build your own RMarkdown document. Master different aspects of RMarkdown syntax. Become familiar with GitHub as a collaborative tool.  Note the following requirements:\n All members of the group must commit at least once. All commit messages must be reasonably clear and meaningful. Your GitHub repository must include at least one issue containing some form of TO DO list.  In your repository, create a RMarkdown file called hw1.Rmd providing an HTML output with the theme cerulean and syntax highlighting tango. This file should contain the following elements:\n A \u0026ldquo;title\u0026rdquo; section which should at least include:  A title (e.g. Homework 1) The authors The date (think of using Sys.time())    In order to do so, it is possible to simply write as a header to your RMarkdown:\n--- title: \u0026#34;Homework 1\u0026#34; author: Samuel Orso \\\u0026amp; Iegor Rudnytskyi date: \u0026#34;`r format(Sys.time(), \u0026#39;%d %B, %Y\u0026#39;)`\u0026#34; output: html_document: theme: cerulean highlight: tango ---  A section called \u0026ldquo;Introduction\u0026rdquo; where you provide a short summary of the structure of your homework. Moreover, record a short video to introduce your group and include it in your RMarkdown document.  To create a section, use a single hash sign (\u0026quot;#\u0026quot;); to create a subsection, use a double hash sign (\u0026quot;##\u0026quot;). Here, one would write, for the introduction:\n# Introduction Here is the intro. Bla bla bla. To add a video below, one would add the following nomenclature, for example for a Youtube video:\n![](https://youtu.be/zNzZ1PfUDNk)  A section called \u0026ldquo;Group Members\u0026rdquo;. This section should have one sub-section for each group member in your team. For example, a group with three members should have three sub-sections. Each of these sub-sections (named after each group member) should include small biographies containing at least the following elements:  A picture of your choice (preferably of yourself). Make sure to include a caption for this image. A paragraph describing your favorite hobby as well as one interesting fact about yourself (preferably true). Your favorite quote in blockquote format. Make sure to reference your quote using BibTex. A table having two columns (first column containing the classes you are following this semester; second column containing the time of these classes).    To do the above, one would for example have the following nomenclature, using LaTeX type format for the table:\n# Group Members ## Samuel Orso Lecturer in Data Science at UNIL,... ![An American logo](http://www.alumni.psu.edu/s/1218/16/images/logo.png) My hobbies are... \u0026gt;\u0026#34;Some mathematician, I believe, has said that true pleasure lies not in the discovery of truth, but in the search for it.\u0026#34; \u0026gt;-- Tolstoi To create a table, one could for example use the kableExtra package and write:\nlibrary(knitr) library(kableExtra) courses.taken \u0026lt;- c(\u0026#34;Applied Mathematics\u0026#34;, \u0026#34;Measure Theory\u0026#34;, \u0026#34;R for Data Science\u0026#34;) time \u0026lt;- c(\u0026#34;08:00\u0026#34;, \u0026#34;08:00\u0026#34;, \u0026#34;09:00\u0026#34;) df \u0026lt;- data.frame(cbind(courses.taken, time)) colnames(df) \u0026lt;- c(\u0026#34;Courses taken\u0026#34;, \u0026#34;Time\u0026#34;) kable_styling(kable(df, \u0026#34;html\u0026#34;))  A section called \u0026ldquo;RMarkdown Syntax\u0026rdquo;, where you will demonstrate your RMarkdown skills! In this section make sure to:  Show an example where the chunk option cache = T leads to a misleading answer. This example must be different from the one presented in the textbook.    For example, this can be use to save some time while generating large random vectors. One example where cache=TRUE can be misleading is when you first start by a chunk of the following form, specifying for the option:\nset.seed(1) a \u0026lt;- rexp(100) and you call a in another chunk, say the following one, with option cache=TRUE:\n(b \u0026lt;- log(a)) without adding as option dependson=(name of the first chunk), since if you first knit with 100 randomly generated exponential numbers and you then change a to rexp(1000), it will cache the value of a and only show you b accordingly.\n Simulate 300 random samples from a distribution that is uniform on [-1, 1] interval using the function runif(). Store these 300 values in a vector called x. Then, compute the empirical median, mean and variance of x. Are these results different from 0, 0 and 1/3 (their respective theoretical values)? Is this result surprising? Justify your answer.  Here is the code to do so:\nset.seed(1) x \u0026lt;- runif(n = 300, min = -1, max = 1) empmean \u0026lt;- mean(x) empmed \u0026lt;- median(x) empvar \u0026lt;- var(x) The values are somewhat different from 0, 0 and 1/3 respectively, not so much but this variation is due to the fact that we only compute sample estimates of population values for the values above. Therefore, there is a natural variation.\n Include a graph showing the density estimation of x (make sure to include a caption to this figure). You can use the R function d \u0026lt;- denstiy() with default parameters, and the plot(d) function. Why does the estimated density exceed the [-1, 1] interval?  One would use the following command:\nd \u0026lt;- density(x) plot(d, main = \u0026#34;Density\u0026#34;) adding as an option to this chunk the option fig.cap=\u0026quot;Density estimation of x\u0026quot; to display a caption to this figure.\nBy default density estimator uses \u0026ldquo;gaussian\u0026rdquo; kernel to construct the curve. Therefore, the points that are close to the borders (-1 and 1) add extra noise, which expands outside of the original interval. This noise may be reduced by decreasing the bandwidth bw, as well as choosing a kernel with finite support, i.e. rectangular or epanechnikov.\n Include the following equation :  \\[ \\begin{aligned} \\left( P^t f \\right) ( \\mathbf{x} ) = f_b ( \\mathbf{x} ) + \\frac{\\sigma^2 t}{2 |D| d} \\int_{\\partial D} \\frac{\\partial f}{\\partial n} \\mathrm{d} \\widehat{\\mathbf{y}} + \\sum c_m^0 \\exp \\left( - \\frac{\\sigma^2 \\widetilde{\\kappa}_m^2 t}{2} \\right) \\widetilde{s}_m ( \\mathbf{x} ) + f_h ( \\mathbf{x} ) \\end{aligned} \\]  Include the following in-line equation:   To do so, use the LaTeX nomenclature as follow:\n$\\hat{f}(\\xi) = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^\\infty f(x) \\, e^{-i x \\xi} \\, \\mathrm{d} x.$  Include the following text in blue: \u0026ldquo;The degree of civilization in a society can be judged by entering its prisons.\u0026rdquo;, Fyodor Dostoevsky  Write:\n\u0026lt;span style=\u0026#34;color:green\u0026#34;\u0026gt;\u0026#34;The degree of civilization in a society can be judged by entering its prisons.\u0026#34;, Fyodor Dostoevsky text\u0026lt;/span\u0026gt;  Include a \u0026ldquo;More info\u0026rdquo; button with hide/unhide functionality.  To do so, use:\n\u0026lt;button data-toggle=\u0026#34;collapse\u0026#34; data-target=\u0026#34;#demo\u0026#34;\u0026gt;More info\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;demo\u0026#34; class=\u0026#34;collapse\u0026#34;\u0026gt; Some additional info... \u0026lt;/div\u0026gt;  Include a \u0026ldquo;color box\u0026rdquo;\u0026quot; with some text.  To do so, use:\n\u0026lt;div class=\u0026#34;alert alert-danger\u0026#34;\u0026gt; \u0026lt;strong\u0026gt;Some important Info:\u0026lt;/strong\u0026gt; something \u0026lt;/div\u0026gt; "
},
{
	"uri": "https://ptds.samorso.ch/homeworks/",
	"title": "Homeworks",
	"tags": [],
	"description": "",
	"content": "Homeworks There are four graded homeworks to be submitted at different deadlines during the semester. The homeworks represent 50% of the final grade. Time management is important for succeeding in this class, try to avoid the following example:\n"
},
{
	"uri": "https://ptds.samorso.ch/tutorials/logistic/",
	"title": "Logistic regression",
	"tags": [],
	"description": "",
	"content": "The aim of this tutorial is to show how to write your own program for estimating a logistic regression. Note that the goal is purely educational since the logistic regression has already solid implementations in R.\nIntroduction Logistic regression is one of most famous tool to model binary data. It is often introduced in under-graduate class of statistics and machine learning.\nFor illustration, we fit a logistic regression on the titanic dataset. This dataset is made available for example via the titanic R package. You can obtain more detail on this dataset by calling the help ? titanic_train, read the package documentation or the Kaggle competition webpage. When installed, R comes already equipped with a rich library called stats which contains the glm function that allows to fit Generalized Linear Model, a broad class of model that includes logistic regression. In the next lines of code, we see an example using this glm function on the titanic dataset.\n## decomment if not installed ## install.packages(\u0026#34;titanic\u0026#34;) library(titanic) # call the library data(\u0026#34;titanic_train\u0026#34;) # load the training dataset fit_logistic \u0026lt;- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare, family = binomial(link = \u0026#34;logit\u0026#34;), data = titanic_train) summary(fit_logistic) Few comments:\n We try to explain the binary data Survived with six different covariates, or explanatory variables. The glm function takes as first argument a formula object, here Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare (check ? formula for more details). The family argument of glm specifies the distribution; for logistic regression it is specified to binomial(link = \u0026quot;logit\u0026quot;). The data argument gives the dataset so names can be directly used in the formula.  The output of the summary is\nCall: glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare, family = binomial(link = \u0026#34;logit\u0026#34;), data = titanic_train) Deviance Residuals: Min 1Q Median 3Q Max -2.7953 -0.6476 -0.3847 0.6271 2.4433 Coefficients: Estimate Std. Error z value Pr(\u0026gt;|z|) (Intercept) 5.389003 0.603734 8.926 \u0026lt; 2e-16 *** Pclass -1.242249 0.163191 -7.612 2.69e-14 *** Sexmale -2.634845 0.219609 -11.998 \u0026lt; 2e-16 *** Age -0.043953 0.008179 -5.374 7.70e-08 *** SibSp -0.375755 0.127361 -2.950 0.00317 ** Parch -0.061937 0.122925 -0.504 0.61436 Fare 0.002160 0.002493 0.866 0.38627 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 964.52 on 713 degrees of freedom Residual deviance: 635.81 on 707 degrees of freedom (177 observations deleted due to missingness) AIC: 649.81 Number of Fisher Scoring iterations: 5 The column Estimate returns the estimators of the logistic regression; this is the quantities we are going to compute in this tutorial. Note that there are 177 observations missing.\nWe can for example visualize these missing values with the VIM library.\n## decomment if not installed ## install.packages(\u0026#34;VIM\u0026#34;) library(VIM) matrixplot(titanic_train) It appears clearly that the variable Age is the only one missing values. There are different way to deal with missing values (glm simply delete the corresponding rows). Here for simplicity we will not consider Age so we have the following model:\nfit_logistic2 \u0026lt;- glm(Survived ~ Pclass + Sex + SibSp + Parch + Fare, family = binomial(link = \u0026#34;logit\u0026#34;), data = titanic_train) summary(fit_logistic2) Call: glm(formula = Survived ~ Pclass + Sex + SibSp + Parch + Fare, family = binomial(link = \u0026#34;logit\u0026#34;), data = titanic_train) Deviance Residuals: Min 1Q Median 3Q Max -2.2340 -0.6786 -0.4817 0.6315 2.5515 Coefficients: Estimate Std. Error z value Pr(\u0026gt;|z|) (Intercept) 3.147350 0.375154 8.389 \u0026lt; 2e-16 *** Pclass -0.835995 0.126848 -6.591 4.38e-11 *** Sexmale -2.759428 0.195930 -14.084 \u0026lt; 2e-16 *** SibSp -0.256350 0.100785 -2.544 0.011 * Parch -0.088766 0.113191 -0.784 0.433 Fare 0.003416 0.002355 1.451 0.147 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 1186.66 on 890 degrees of freedom Residual deviance: 816.75 on 885 degrees of freedom AIC: 828.75 Number of Fisher Scoring iterations: 5 Logistic regression model In probability theory, a random variable $Y$ that takes value $1$ with probability $p$ and $0$ with probability $1-p$ is called a Bernoulli random variable. We can write this statement as $\\Pr(Y=1)=p$ and $\\Pr(Y=0)=1-p$ where $p\\in(0,1)$ is often called the probability of success. We can write the same statement more compactly as $$\\Pr(Y)=p^Y(1-p)^{1-Y}.$$\nThe logistic regression model replaces this probability of success by the sigmoid function $$\\sigma(t)=\\frac{1}{1+e^{-t}}.$$ Generally we express further $t$ as a linear combination of known covariates $x$ and unknown coefficients $w$ as follows: $$t = w _0 + \\sum _{j=1} ^{p} x _j w _j,$$\nor more compactly in matrix form\n$$t = Xw,$$\nwhere the first column of $X$ is $1$\u0026rsquo;s and $w=(w _0, \\ldots , w _{p})^{T}$. In this tutorial we are interested in estimating the coefficients $w$ and we are going to use the maximum likelihood estimator (MLE).\nMLE for Bernoulli random variables Maximum likelihood estimator? Suppose you obtained $n$ observations, for example as follows:\np \u0026lt;- .25 n \u0026lt;- 10 set.seed(9842) y \u0026lt;- rbinom(n,size=1,prob=p) y (note that we use rbinom() as Bernoulli distribution is a special case of the binomial distribution, which maybe also explain the family argument used before.)\n[1] 0 0 0 0 0 0 0 1 0 1 but you don\u0026rsquo;t know the parameter $p$. So a question is, what is this value? One way to answer this problem is to consider the likelihood function, a function that measures how probable is a given data as a function of the parameter. Denote this function by $\\mathcal{L}(p;y)$. The idea is to find the value $p$ that maximizes $\\mathcal{L}(p;y)$. For example, if we have two values $p_1,p_2$ and we have $\\mathcal{L}(p_1;y)\u0026gt;\\mathcal{L}(p_2;y)$, then $p_1$ is more plausible than $p_2$, there is more chance the data was generated by $p_1$ than by $p_2$. The maximum of this likelihood function is called the maximum likelihood estimator.\nFor $n$ i.i.d. Bernoulli random variables, the likelihood function is\n$$\\mathcal{L}(p;y)=\\prod_{i=1}^n p^{y_i}\\left(1-p\\right)^{1-y_i}$$\nor equivalently $$p^{s_n}\\left(1-p\\right)^{n-s_n},$$ where $ s _n = \\sum _{i=1} ^n y _i .$\nWe illustrate this function below.\n## define the likelihood function f \u0026lt;- function(p,y){ p^sum(y) * (1-p)^(length(y) - sum(y)) } p_hat \u0026lt;- mean(y) # maximum likelihood estimator ## plot the likelihood function plot(NA, xlim = c(0,1), ylim=c(0,7e-3), xlab = \u0026#34;p\u0026#34;, ylab = \u0026#34;likelihood function\u0026#34;, main = \u0026#34;Maximum likelihood estimator of Bernoulli distribution\u0026#34;, cex.main = .9) grid() curve(f(p,y),from = 0,to = 1, xname = \u0026#34;p\u0026#34;, lwd = 3, add = TRUE, col = \u0026#34;gray30\u0026#34;) points(x = p, y = f(p,y), pch = 17, col = \u0026#34;#990000\u0026#34;, cex = 1.5) points(x = p_hat, y = f(p_hat,y), pch = 17, col = \u0026#34;#009999\u0026#34;, cex = 1.5) legend(\u0026#34;topright\u0026#34;, legend = c(\u0026#34;Parameter\u0026#34;,\u0026#34;Estimator\u0026#34;), col = c(\u0026#34;#990000\u0026#34;,\u0026#34;#009999\u0026#34;), pch = 17, pt.cex = 1.5, bty = \u0026#34;n\u0026#34;) We clearly see the likelihood function is a concave function (how would you verify this analytically?), so one way to compute its maximum is to find the point such that the slope of the function is zero. It is generally more convenient to work with the log-likelihood function $\\ell(p;y)=\\log(\\mathcal{L}(p,y))$. Taking the logarithm does not change the maximum. The first derivative of the log-likelihood is\n$$\\frac{ \\partial \\ell(p;y) }{ \\partial p} = \\frac{s _n}{p} - \\frac{ n - s _n}{1-p}.$$\nSolving $\\partial\\ell(p;y)/\\partial p = 0$ leads to the unique solution $ \\hat{p} = s _n / n$ (if $0 \u0026lt; s _n / n \u0026lt; 1$).\nMLE for logistic regression For the logistic regression, the computations are slightly more involved. Suppose you observe $n$ binary data, the likelihood function is $$\\mathcal{L}(w;y,X)=\\prod_{i=1}^n\\sigma(t_i)^{y_i}\\left(1-\\sigma(t_i)\\right)^{1-y_i}.$$ Similarly, le log-likelhood is given by\n$$\\ell(w;y,X) = \\sum _{i=1} ^{n} y _{i} \\log\\left(\\frac{\\sigma(t _{i})}{ 1 - \\sigma(t _{i})}\\right) + \\log\\left(1-\\sigma(t _{i})\\right),$$\nwhere $$\\sigma(t _{i}) = \\frac{1}{ 1 + \\exp( -x _{i}w)}$$\nand $x _i$ is the ith row of $X$ (row-vector). Some manipulations lead to a simpler expression: $$\\ell(w;y,X) = \\sum _{i=1} ^{n} y _{i} x _{i} w - \\sum _{i=1} ^{n} \\left(1+e ^{x _{i} w}\\right).$$ The gradient of the log-likelihood function is given by $$\\frac{\\partial}{\\partial w} \\ell(w;y,X) = \\sum _{i=1} ^n y _i x _i ^T - \\sum _{i=1} ^n \\frac{e ^{x _i w}}{1+e ^{x _i w}}x _i ^T.$$ It is possible to simplify this expression with the following matrix notation $$ \\frac{\\partial}{\\partial w}\\ell(w;y,X) = X ^T ( y - \\sigma _n (t)),$$ where $\\sigma _n (t)$ is a vector with ith element $\\sigma(t _i)$.\nIn the case of the Bernoulli distribution, we were able to find the zero of gradient analytically. Here for the logistic regression, it is impossible so we will use optimisation techniques. Generally, optimisers are programmed for minising a function so we need to consider the negative log-likelihood instead, that is simply putting a minus sign in the above calculations.\nBefore optimising, let\u0026rsquo;s first program these functions\n## negative log-likelihood nll \u0026lt;- function(w,X,y){ xw \u0026lt;- X %*% w - y %*% xw + sum(log(1 + exp(xw))) } ## sigmoid function sigmoid \u0026lt;- function(t){ 1 / (1 + exp(-t)) } ## gradient grad_nll \u0026lt;- function(w,X,y){ xw \u0026lt;- X %*% w t(X) %*% (sigmoid(xw) - y) } In R, there is an optim function from that stats library that allows to make optimisation.\nRecall that we are interested in the titanic dataset so we use the following data, taking from the logistic fit:\nX \u0026lt;- model.matrix(fit_logistic2) y \u0026lt;- fit_logistic2$y optim is equipped with different routines; check the help help(optim) and for example this page for some explanations. Here we use the BFGS algorithm (Broyden-Fletcher-Goldfarb-Shanno).\nopt_bfgs \u0026lt;- optim(par = rep(0,6), fn = nll, gr = grad_nll, method = \u0026#34;BFGS\u0026#34;, y = y, X = X) opt_bfgs Few comments:\n par: a starting value is required, here we set $w^{(0)}=0$. fn: the objective function (negative log-likelihood). gr: (optional) the gradient. method: the choice of algorithm. y,X: the specific extra argument necessary for nll() and grad_nll().  The output is\n$par [1] 3.147127868 -0.835901451 -2.759108265 -0.256122427 -0.088817088 [6] 0.003413478 $value [1] 408.3751 $counts function gradient 43 14 $convergence [1] 0 We see:\n par: the values that minises nll() found by the algorithm. value: the value of the objective function when evaluated at par. counts: the number of time the algorithm evaluated the different functions. convergence: a value of 0 indicates the algorithm converged.  Now let\u0026rsquo;s compare with what glm obtained:\ncbind(coef(fit_logistic2), opt_bfgs$par, abs(coef(fit_logistic2)-opt_bfgs$par)) [,1] [,2] [,3] (Intercept) 3.14734995 3.147127868 2.220822e-04 Pclass -0.83599490 -0.835901451 9.345216e-05 Sexmale -2.75942799 -2.759108265 3.197251e-04 SibSp -0.25635020 -0.256122427 2.277746e-04 Parch -0.08876554 -0.088817088 5.154484e-05 Fare 0.00341621 0.003413478 2.731828e-06 The third column indicates the absolute difference, not too far!\nNote that glm is based on a different algorithm, the iterative reweighted least squares (check that for more infos). Want to go further and program the logistic regression using Rcpp, check the example here\n"
},
{
	"uri": "https://ptds.samorso.ch/syllabus/communication/",
	"title": "Communication",
	"tags": [],
	"description": "",
	"content": "Slack We will be using Slack for class-related discussion and questions, to help you benefit from each other’s questions and the collective knowledge of your classmates and instructors. Questions can be posted to the entire class (for content-related questions). I encourage you to ask questions if you are struggling to understand a concept, and to answer your classmates’ questions when you can.\nEmail Most matters, public or private, should be addresssed through Slack.\n"
},
{
	"uri": "https://ptds.samorso.ch/homeworks/hw2/",
	"title": "homework #2",
	"tags": [],
	"description": "",
	"content": " Deadline: 2021-10-24 11:59pm\nTo submit your work, simply push it to the dedicated repository created for your group.\nWe will grade only the latest files prior to the deadline. Any ulterior modifications are pointless.\n The objectives of this homework assignment are the followings:\n Learn how program effectively using if/else and iterations statements; Become familiar with using data frame objects and mapping packages; Constructing a portfolio; Become familiar with GitHub and use it as a collaborative tool.  This project must be done using GitHub and respect the following requirements:\n All members of the group must commit at least once. All commit messages must be reasonably clear and meaningful. Your GitHub repository must include at least one issue containing some form of TO DO list. Organization (separation of work,\u0026hellip;) and progress for your group must appear clearly in GitHub Projects.  You can create one or several RMarkdown files to answer the following problems:\nProblem 1: Are you a power? Write a program that prints the numbers from 1 to 100, but with the specific requirement:\n if the number is a full square of another number $a$, print a^2; if the number is a full cube of another number $b$, print b^3; if the number is a full square of another number $a$ and a full cube of another number $b$, print a^2, b^3.  An example of the output would be:\n\u0026#34;1^2, 1^3\u0026#34; \u0026#34;2\u0026#34; \u0026#34;3\u0026#34; \u0026#34;2^2\u0026#34; \u0026#34;5\u0026#34; \u0026#34;6\u0026#34; \u0026#34;7\u0026#34; \u0026#34;2^3\u0026#34; \u0026#34;3^2\u0026#34; \u0026#34;10\u0026#34; \u0026#34;11\u0026#34; \u0026#34;12\u0026#34; \u0026#34;13\u0026#34; \u0026#34;14\u0026#34; \u0026#34;15\u0026#34; \u0026#34;4^2\u0026#34; \u0026#34;17\u0026#34; \u0026#34;18\u0026#34;, ... Problem 2: Map This exercise is designed as a guided tutorial to the basic functions of the leaflet and maps packages that allow to draw maps and display information on them. First of all, if not done already, install leaflet and maps and load them into R.\n (a) Create a simple map by using the addTiles() function with its first argument being leaflet() and display the resulting map. (b1) On the map from point (a), add a marker with the help of the addMarkers function at $(\\text{lon}, \\text{lat})=(6.581188,46.522451)$ with a popup message specifying \u0026ldquo;University of Lausanne\u0026rdquo;. (b2) On the same map display one favorite place in Switzerland for each member of your team. To do so, create a data.frame (or tibble), find all corresponding coordinates, add the names of the places, add use addMarkers to the result of (b1). (c) Using the map function from the maps package, display a map of Italy with different colors for the various regions in this country, using the addPolygons function. See color options for filling the polygons. (d) Download and load the ETAS package in order to retrieve some earthquakes data for Italy, that are stored in the aforementioned package as italy.quakes (assign it to a variable into your R). Filter for earthquakes of magnitude greater than (or equal to) 4.0 on the Richter scale and add markers with popups on the various localization of these earthquakes with their respective magnitudes. (e) On the previous map in point (d), instead of simple markers, add circle for each of the earthquake using the addCircles function and let the size of the circle vary with the magnitude of the earthquake. Add markers for the earthquakes that have more or equal than 5.0 magnitude with a popup of the corresponding number. Finally, use addLayersControl to distinguish on the map between two types of datatips (groups): the circles of all earthquakes, and the markers of the earthquakes of a magnitude 5.0 or higher, using the overlayGroups parameter. Your final map should look similar to the following:  Problem 3: Stock price and European call option Let a stock price at time $t$ be $S(t) \\equiv S_t$. Assume that $S(t)$ follows a Geometric Brownian Motion (GBM) given by:\n$$\\mathrm{d}S_t = r,S_t + \\sigma , S_t , \\mathrm{d}W_t, \\quad 0 \u0026lt; t \u0026lt; 1,$$\nwhere $S(0) = 1$, $r$ is a percentage drift, $\\sigma$ is a percentage volatility, and $W_t$ is a Brownian motion.\nTo simulate from this continuous time series model one can use the Euler-Maruyama discretisation method with a constant temporal step $\\tau$:\n$$S_{m+1} = S_m + r,S_m,\\tau + \\sigma,S_m,\\Delta W_m, \\quad S_0 = 1,$$\nwhere $\\Delta W_m$ are i.i.d. centered normally distributed random variables with variance $\\tau$, $m = 0, 1, 2, \\ldots, N_t - 1$, $N_t = \\text{ceiling}(1/\\tau) + 1$ is the number of temporal steps at which the values $S_m$ are calculated (including $0$ and the first temporal step that exceeds $1$, if necessary).\nA European call option with the strike price $K$ can be expressed as\n$$Y = \\exp(-r) \\cdot \\max\\{0; S(1) - K\\}.$$\nThe value of $Y$ can be approximated using a Monte-Carlo method: consider $N$ Euler-Maruyama simulations of the paths $S(t)$; for each simulation $n = 1, 2, \\ldots, N$ calculate $Y _{n}$ using the above mentioned formula; eventually, approximate the value of $Y$ by taking the mean $\\bar{Y} = \\sum _{n=1}^{N} Y _{n}$.\nFor the following parameters\n   Parameter Value     $r$ 0.05   $\\sigma$ 0.2   $\\tau$ 0.001   $K$ 1   $N$ 500      (a) Simulate $N$ paths of the stock price $S(t)$ using the Euler-Maruyama method. Plot some of these paths and comment on them. Do you think this model reflect what you could observe on the stock market? What features seem striking?\n  (b) Calculate $N$ European call option prices $Y_n$, $n = 1, 2, \\ldots, N$ and plot the average option price Y_bar = mean(Y_n). Is it what you were expecting?\n  (c) Find and plot with a green color the path $S(t)$ versus the time $t$, which led to the highest value of the option price, i.e. the path $S(t)$ corresponding to $\\max(Y_n)$;\n  (d) On the same graph plot the path $S(t)$, which led to the lowest value of the option price, i.e. the path $S(t)$ corresponding to $\\min(Y_n)$;\n  (e) Finally, on the same graph plot the path $S(t)$, which led to the value $Y_k$ that is the closest to the estimate $\\bar{Y}$, i.e. the path $S(t)$ corresponding to $\\min(|Y_n - \\bar{Y}|)$.\n  Problem 4: portfolio construction Suppose that you are working in an investment firm company as a quantitative analyst. Your boss gives you the task of creating a portfolio for one of your client. The client wants to find the portfolio with the smallest variance that satisfies the following constraints:\n Invest exactly $1,000,000. Invest in exactly two stocks of the S\u0026amp;P500 index.  Therefore, your boss requires that you compute all possible portfolios that satisfy the client\u0026rsquo;s constraints, represent them graphically as (for example) in the graph below and find the weight of the best (i.e. minimum variance) portfolio.\nIn order to complete this task, the boss tells you to use 3 years of historical data. The boss also mentions that the functions get() and ClCl() could be useful for this project and provides you with the example below (what a really nice boss!):\nlibrary(quantmod) library(rvest) sp500 \u0026lt;- read_html(\u0026#34;https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\u0026#34;) sp500 %\u0026gt;% html_nodes(\u0026#34;.text\u0026#34;) %\u0026gt;% # \u0026#34;td:nth-child(1) .text\u0026#34; should be used instead html_text() -\u0026gt; ticker_sp500 SP500_symbol \u0026lt;- ticker_sp500[(1:499)*2+1] # Replace \u0026#34;.\u0026#34; by \u0026#34;-\u0026#34; SP500_symbol \u0026lt;- gsub(\u0026#34;.\u0026#34;,\u0026#34;-\u0026#34;,SP500_symbol,fixed=T) # Specify timing tot_length \u0026lt;- 3 * 365 today \u0026lt;- Sys.Date() seq_three_years \u0026lt;- seq(today,by=-1,length.out=tot_length) three_year_ago \u0026lt;- seq_three_years[tot_length] # Retrieve data for a stock i \u0026lt;- 1 getSymbols(SP500_symbol[i],from=three_year_ago,to=today) stock_price \u0026lt;- ClCl(get(SP500_symbol[i])) "
},
{
	"uri": "https://ptds.samorso.ch/homeworks/hw3/",
	"title": "homework #3",
	"tags": [],
	"description": "",
	"content": " Deadline: 2021-11-14 11:59pm To submit your work, simply push it to the dedicated repository created for your group.\nWe will grade only the latest files prior to the deadline. Any ulterior modifications are pointless.\n The objectives of this homework assignment are the followings:\n Become competent at programming effectively using if/else and iterations statements; Learn how to program effectively using functions and think like a programmer; Improve your collaborative skills via GitHub.  This project must be done using GitHub and respect the following requirements:\n All members of the group must commit at least once. All commit messages must be reasonably clear and meaningful. Your GitHub repository must include at least one issue containing some form of TO DO list.  You can create one or several RMarkdown files to answer the following problems:\nProblem 1: Finding area of a shape In this problem, we consider a Monte-Carlo approach for approximating the area of a shape $S$ (that you assume you do not know). To start with, let us consider a unit square, which has an area of 1, and consider the shape $S$, which is an intersection of three regions $S = D_1 \\cap D_2 \\cap D_3 $, where\n$$D_1: x^2 + y^2 \u0026gt; 0.5^2; \\quad D_2: (x - 0.5)^2 + (y - 0.5)^2 \u0026lt; 0.5^2; \\quad D_3: y \u0026gt; x - 0.5.$$\nLet us assume that the x and y coordinates are uniformly distributed between 0 and 1, that is $X\\sim\\mathcal{U}(0, 1)$ and $Y\\sim\\mathcal{U}(0, 1)$. We consider the following method for estimating the area of this circle:\n Simulate $B$ coordinates $[X_i,; Y_i]^T$, $i=1,\\dots,B$. Create a vector of Booleans $Z$, such that $Z_i = 1$ if $(X_i, Y_i) \\in S$ and 0 otherwise. Estimate $\\mathrm{area}(S)$ as follows:  $$\\text{area of the square } \\times \\frac{\\text{number of points in the } S}{\\text{total number of points}} = \\frac{\\sum_i^B Z_i}{B}.$$\nIf you want to understand why this method works, see the bottom of the page.\na) Create a function that approximates $\\mathrm{area}(S)$ following the above recipe. Your function should be called find_area() and should have three arguments:\n B: the number of points for the approximation with defaults value = 5000, seed: a positive integer that controls the generation of random numbers with default value = 10, make_plot: a Boolean value that control whether or a not a graph should be made (see below for details and use FALSE as default).  Your function should look like:\nfind_area \u0026lt;- function(B = 5000, seed = 10, make_plot = FALSE){ # Control seed set.seed(seed) # Simulate B points point = matrix(runif(2*B, 0, 1), nrow = B, ncol = 2) ... return(area_hat) } When enabling the plot by setting make_plot = TRUE, the function find_area() should produce a graph with a square, the shape of $S$ inside, and the B points with two distinct colors according to whether the point is inside or outside the circle. See below for an example. b) Verify that by running find_area(B=10^6, make_plot = TRUE) the function returns the value $0.571741$. Compare it to the real area of the shape $S$ (calculate it using simple school formulas).\nProblem 2: Satellite Navigation System Global Navigation Satellite Systems or GNSS are systems with global coverage that uses satellites to provide autonomous geo-spatial positioning. They allow small electronic receivers to determine their location (longitude, latitude, and altitude/elevation) to high precision (within a few meters) using time signals (i.e. \u0026ldquo;distances\u0026rdquo; informally speaking) transmitted along a line of sight by radio from satellites. Currently, there exist only three global operational GNSS, the United States' Global Positioning System (GPS), Russia\u0026rsquo;s GLONASS and the European Union\u0026rsquo;s Galileo. However, China is in the process of expanding its regional BeiDou Navigation Satellite System into a global system by 2020. Other countries, such as India, France or Japan are in the process of developing regional and global systems.\nObviously, GNSS are very complex systems and in this exercise we will consider an extremely simplified setting to illustrate the basic concepts behind satellite positioning. If you are interested in learning more about GNSS, an excellent introduction to get started this topics can be found here: \u0026ldquo;An Introduction to GNSS\u0026rdquo;.\nFor simplicity, let us start by assuming that the earth is a motionless perfect circle in a two-dimensional space. Next, we assume that three motionless GNSS-like satellites are placed around the earth. The position of these satellites is assumed to be known and we will assume that there are synchronized (i.e. they all have the same \u0026ldquo;time\u0026rdquo;). Our simplified setting can be represented as follows: Now, suppose that you are somewhere on our flat earth with a GNSS-like receiver. The way you will be able to compute your position with such system is by first determining the distance (or a closely related notion) between yourself and with each satellite. The computation of these distances is done by comparing the time at which a signal is emitted by a satellite and the time at which it is received by your device. More precisely, let $t_e^{(i)}$ and $t_r^{(i)}$ denote, respectively, the times at which a signal is emitted and received for satellite $i$. To simplify further, we assume that $t_e^{(i)}$ (also known as the clock in each satellite) is \u0026ldquo;perfect\u0026rdquo; (this point may surprise you, but in reallity the time in the satellite are subjected to random variations). However, the clock in our device is not perfect and $t_r^{(i)}$ is estimated by $\\hat{t}_r^{(i)}$ which represents the time recorded by the receiver device. Since all satellites are assumed to be synchronized, we can write $$\\hat{t}_r^{(i)} = t_r^{(i)} + \\Delta t,$$ where $\\Delta t$ is the time difference, it is the same for all satellites as it does not depend on $i$. Using this simple result as well as the times $\\hat{t}_r^{(i)}$ and ${t}_e^{(i)}$, we can compute the estimated distance between us and the $i$-th satellite as follows:$$ \\hat{d}_i = c\\left[(t_r^{(i)} + \\Delta t) - t_e^{(i)}\\right] = c\\left(t_r^{(i)} - t_e^{(i)}\\right) + c \\Delta t = d_i + \\varepsilon,$$ where $c$, $d_i$ and $\\varepsilon$ denote, respectively, the speed of the signal, the true distance between us and the $i$-th satellite, and the measurement error. This setting can be represented as follows: Next, we let $(x_i, y_i), , i = 1,2,3$ denote the position of satellite $i$. The coordinates of these points are given in the table below:\n   $i$ $x_i$ $y_i$     1 -300 300   2 300 300   3 0 -300    Finally, we let $(x_0, y_0)$ denotes our position on earth. Then, the distance between our position and the $i$-th satellite is given by $$ d_i = \\sqrt{\\left(x_i - x_0\\right)^2 + \\left(y_i - y_0\\right)^2}. $$ Unfortunately, $d_i$ is unknown (if our position were known, why using a GNSS system). Instead, we can express the distance as $d_i = \\hat{d}_i - \\varepsilon$. We obtain following system of equations: $$ \\begin{aligned} (x_1 - x_0)^2 + (y_1 - y_0)^2 \u0026amp;= (\\hat{d}_1 - \\varepsilon)^2 \\\\ (x_2 - x_0)^2 + (y_2 - y_0)^2 \u0026amp;= (\\hat{d}_2 - \\varepsilon)^2 \\\\ (x_3 - x_0)^2 + (y_3 - y_0)^2 \u0026amp;= (\\hat{d}_3 - \\varepsilon)^2, \\end{aligned} $$ where $\\boldsymbol{\\theta}=[x_0;;y_0;;\\varepsilon]^T$ are the three unknown quantities we wish to estimate and $\\hat{d}_i,;i=1,2,3,$ are the observations.\nWhile there exists several methods to solve such estimation problem, the most common is known as the \u0026ldquo;least-square adjustement\u0026rdquo; and will be used in this problem. It is given by: $$ \\hat{\\boldsymbol{\\theta}} = \\operatorname{argmin}_{\\boldsymbol{\\theta}} ; \\sum_1^3 ; \\left[\\left(x_i - x_0\\right)^2 + \\left(y_i - y_0\\right)^2 - \\left(\\hat{d}_i - \\varepsilon\\right)^2\\right]^2. $$\na) Write a general function named get_position() that takes as a single argument a vector of observed distances and returns an object with an appropriate class having custom summary and plot functions. For example, suppose we observe the vector of distances $$ \\hat{\\mathbf{d}} = [\\hat{d}_1;;\\hat{d}_2;;\\hat{d}_3]^T = [449.2136;;284.8427;;414.3106]^T, $$ then you should replicate (approximately) the following results:\nposition = get_position(c(453.2136, 288.8427, 418.3106)) summary(position) ## The estimated position is: ## X = 99.9958 ## Y = 100.003 plot(position) Note that inside the get_position() function, you need to estimate the positions $\\hat{x}$ and $\\hat{y}$. You can use the R function optim for this purpose. It has the syntax:\noptim(par = starting_values, fn = my_objective_function, arg1 = arg1, ..., argN = argN) The arguments are:\n starting_values: the starting values for the optimization, here a vector of three values corresponding to $\\hat{\\boldsymbol{\\theta}}$. my_objective_function: the objective function, here the one we defined above. It must have $\\boldsymbol\\theta$ as one of its arguments. arg1 to argN: additional arguments for the objective functions.  b) Generalize the function get_position() of the point a) to accept also a matrix of observed distances (but keep only one argument!).\nc) Verify that the function you wrote at the point b) display the same graph\nposition = get_position(dist_mat) summary(position) where the matrix inputed is\n## [,1] [,2] [,3] ## [1,] 458.9474 337.1013 363.1112 ## [2,] 337.0894 458.9355 363.0993 ## [3,] 442.5835 442.5835 283.9493 ## [4,] 520.1845 520.1845 184.0449 ## [5,] 534.1411 499.0299 191.3455 ## [6,] 499.1322 534.2434 191.4479 ## [7,] 542.0904 470.4216 212.7515 ## [8,] 470.4070 542.0758 212.7369 ## [9,] 541.6032 429.4569 250.9978 ## [10,] 429.4120 541.5583 250.9528 Problem 3 This exercise is dedicated to code your own \u0026ldquo;logistic regression\u0026rdquo; using any arbitrary probability function and the optim() function.\nRecall the tutorial on logistic regression, where a probability of success is defined by the sigmoid function $\\sigma(t) = (1 + e^{-t})^{-1}$. Now, to determine the probability of success we consider the CDF of a standard Cauchy distribution\n$$\\sigma(t) = \\frac{1}{\\pi} \\arctan (t) + \\frac{1}{2}.$$\nSimilarly to the tutorial, further we express $t$ as a linear combination of known covariates $x$ and unknown coefficients $w$:\n$$t = Xw.$$\nWe will compare a standard glm fit for the titanic data set with family = binomial(link = \u0026quot;logit\u0026quot;) to our own model. Your goal is to code the log likelihood function $\\mathcal{L}$ of our model, fit the standard glm model for the training set (follow the tutorial), fit the Cauchy model, and finally, compare the results on the test set.\n(a) Load the titanic data set. Create a training set data_train being $70%$ of the data, and a test set data_test - the remaining $30%$. Keep only the Survived, Pclass, Sex, SibSp, Parch, Fare columns. Fit the logistic regression on the training set with Survived being the response variable.\n(b) Code the negative log likelihood function nll(w, X, y), where w is a vector of unknown coefficients; X is a matrix $n \\times 5$ of the observations; y is the response variable. Use optimisation function optim() with target nll and method = \u0026quot;BFGS\u0026quot;.\n(c) For both models calculate the survival probability of data_test. Using a threshold of 0.5, predict the survival as $\\text{Survive} = \\text{Prob} \u0026gt; 0.5$. Create two confusion matrices using, for example, table(), and compare the accuracies of both models. Which model performs better?\nProblem 4 This exercise aims to be a guided tutorial towards building your own (simple) neural network. It is entirely based on James Loy\u0026rsquo;s tutorial on how to do so on Python.\nA neural network is, briefly speaking, a way to map input data to output data using mathematical functions along in order to do so. In a neural network, you have inputs, call them $x$, constituting the input layer; you have an arbitrary number of hidden variables in an arbitrary number of hidden layers; an output layer, call it $\\hat{y}$; a set of weights $\\mathbb{W}$ and biases $\\mathbb{b}$ and, finally, an activation function $\\sigma$ for each hidden layer, that \u0026ldquo;transports\u0026rdquo; your inputs by scaling them with the weights and adding noises with the biases to finally give you your output layer.\nFor simplicity in this tutorial, we will consider the biases to be equally 0 and the network to only have a single hidden layer. The following picture, taking again from James Loy\u0026rsquo;s tutorial, should graphically clarify the situation.\nThe output of a neural network with one hidden layer is given by considering the following function: $$\\hat{y} = \\sigma(W_2 \\sigma(W_1 x + b_1) + b_2)$$ and since we consider the biases to be 0, in our case, it boils down to specify $$\\hat{y} = \\sigma(W_2 \\sigma(W_1 x)). $$\nWe will also impose a parametric form for $\\sigma$ by taking the sigmoid function, which possesses nice properties in this context (among which non-linearity and differentiability), which is given by: $$\\sigma(x) = \\frac{1}{1+e^{-x}}.$$\nWe will start by imposing some random values to the weights and we will update them by \u0026ldquo;training\u0026rdquo; the neural network, which consists of two steps: the feedforward step and the back propagation step:\n The feedforward step consists of computing $\\hat{y}$ and to consequently compute the loss function (or cost function) which measures the difference between the observed output and its computed value; The back propagation consists of updating the weights $W_1$ and $W_2$ in order to reduce the value of the loss computed in the first step.  Graphically, the following picture should clarify the situation, taken again from James Loy\u0026rsquo;s tutorial:\nNow that the setting is clarified, we will build the neural network step by step.\n(a) Create a matrix containing the following 4 observations (inputs):\nand a vector containing the following 4 outcomes, corresponding to the 4 observations above:\n(b) Generate a 3x4 matrix of weights ($W_1$), each uniformly generated between 0 and 1. Then, create a list storing the state of the neural net (to be updated in the training of the neural net), which consists of the inputs, the weights ($W_1$ and $W_2$ (noting that $W_2$ is a vector of 4 random uniform weights)), the outputs and the predicted outputs (create it as a 4x1 matrix with 0s as initial values).\n(c) Create and store the sigmoid function (as a function of a generic x) into R. Then, create the derivative of this function.\n(d) Create and store the loss function (as a function of a generic neural net as created in part b)) into R. For the purpose of this exercise, we assume that the loss (or cost) is simply the sum of the squared errors, i.e. $$\\text{loss}(y, \\hat{y})=\\sum_{i=1}^n (\\hat{y}-y)^2.$$\n(e) Create the feedforward function (as a function of a generic neural net as created in part b)). To do so, use the sigmoid function from point c): in particular, assign to the first layer of the neural net the value of the sigmoid of the matrix product of the input layer with the weights $W_1$. Then, assign to the output of the neural net the value of the sigmoid of the matrix product of the first layer of the neural net with the weights $W_2$. Note that the matrix multiplication is undertaken by using the operator %*% in R. Do the operations in the order mentioned.\n(f) Create the back propagation function (as a function of a generic neural net as created in part b)). To do so, we will update the weights by a gradient descent-type procedure. This works as follow:\n Create the derivative of the loss function with respect to $W_2$: using the chain rule, it can be shown that this derivative is given by:  $$ (\\frac{1}{1+e^{-xW_1}})^T \\times 2(\\hat{y}-y) \\cdot ( \\frac{1}{1+e^{-W_2 \\frac{1}{1+e^{-xW_1}}}} \\cdot (1-\\frac{1}{1+e^{-W_2 \\frac{1}{1+e^{-xW_1}}}}) ) $$\nHints: The above subscript $T$ denotes the transpose of the matrix (obtain it using the t() function in R). The $\\times$ operator denotes a matrix product, whereas $\\cdot$ denotes a regular multiplication. Obtain it by using Note that $\\frac{1}{1+e^{-xW_1}}$ is the layer created using the feedforward function. Also, note that the last part is simply the sigmoid derivative evaluated at the output created using the feedforward function above. So both of these elements are stored in the neural net you input to the backpropagation function and therefore, the above derivative should not be that hard to write.\n Create the derivative of the loss function with respect to $W_1$: using the chain rule, it can be shown that this derivative is given by:  $$ x \\cdot ( 2(\\hat{y}-y) \\cdot ( \\frac{1}{1+e^{-W_2 \\frac{1}{1+e^{-xW_1}}}} \\cdot (1-\\frac{1}{1+e^{-W_2 \\frac{1}{1+e^{-xW_1}}}}) \\times (W_2)^T ) \\cdot (\\frac{1}{1+e^{-xW_1}} \\cdot (1-\\frac{1}{1+e^{-xW_1}}) )$$\nThe notation is as before. Note that $x$ is retrieved from the output of the neural net that is an argument of the function. Also note that $\\frac{1}{1+e^{-xW_1}} \\cdot (1-\\frac{1}{1+e^{-xW_1}}) $ is the sigmoid derivative evaluated at the layer obtained above.\nThen, update weights1 by adding the derivative with respect to $W_1$ obtained above and update weights2 by adding the derivative with respect to $W_2$ also obtained above. Return the resulting neural net as an output of this function.\n(g) \u0026ldquo;Train\u0026rdquo; the neural network: iterate feedforward and backpropagation 1500 times on the neural net created in b). Store the values of the loss function along the iterations to be able to plot it. Then display the predicted vs the actual observation.\nTechnical explanations around problem 1 To understand why the method presented indeed calculates the area of the shape, let us show that $$\\mathbb{E}\\left[Z_i\\right] = \\text{area}(S).$$ To prove this result, we start by noticing that $f(x,y) = f_X (x) f_Y (y) = 1$ if $x\\in[0, 1]$ and $y\\in[0, 1]$ and 0 otherwise.\nLet $Z_i = 1$ if $(X_i, Y_i) \\in S$ and 0 otherwise. Then, we obtain\n$$\\mathbb{E}\\left[Z_i\\right] = \\iint_S f(x, y) dx,dy = \\iint_S dx,dy = \\text{area}(S).$$\nFinally, to estimate the area of $S$ we perform the Monte-Carlo simulations to estimate $\\mathbb{E}[Z_i]$.\n"
},
{
	"uri": "https://ptds.samorso.ch/syllabus/material/",
	"title": "Material",
	"tags": [],
	"description": "",
	"content": "Laptops Bring a laptop to the class every week if you have one. We encourage students to work collaboratively, so we would like to have at least one laptop for every 2 or 3 students. Since the homeworks and the project are the work of a team, we encourage you to team-up with students that possess a laptop. In the case you plan to buy a laptop, remember that the students from Swiss Universities have preferential prices via the Neptun Projekt or the EPFL\u0026rsquo;s Poseidon.\nYou do not need to buy a laptop if you do not possess one.\n OS It is possible to follow this class using Mac OS, Windows and Linux. Yes, Linux. Why not Linux? See https://itsfoss.com/linux-better-than-windows/, https://www.profolus.com/topics/advantages-and-disadvantages-of-macos/ and http://jobsinthefuture.com/index.php/2018/03/02/best-operating-system-os-for-data-science/.\nTextbooks This class is based on the online textbook:\n Required: An Introduction to Statistical Programming Methods with R  This document is under development and it is therefore preferable to always access the text online to be sure you are using the most up-to-date version. Due to its current development, you may encounter errors ranging from broken code to typos or poorly explained topics. If you do, please let us know! Simply add an issue to the GitHub repository used for this document and we will make the changes as soon as possible. In addition, if you know RMarkdown and are familiar with GitHub, make a pull request and fix an issue yourself, otherwise, if you\u0026rsquo;re not familiar with these tools, they will be explained later on in the book itself.\nThe textbooks below are also recommended and are legally available online for free. The following texts will be heavily referenced:\n Recommended: Advanced R Programming by Hadley Wickham Recommended: R Packages Hadley Wickham by Hadley Wickham Recommended: An Introduction to R by W. N. Venables, D. M. Smith, and the R Core Team Recommended: blogdown: Creating Websites with R Markdown by Yihui Xie, Amber Thomas and Alison Presmanes Hill Recommended: R Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, Garrett Grolemund Recommended: Mastering Shiny by Hadley Wickham Recommended: Happy Git and GitHub for the useR by Jennifer Bryan  The following textbooks are helpful, but not necessary to succeed in the course:\n Supplemental: ggplot2: Elegant Graphics for Data Analysis (2nd Edition - GitHub Only) by Hadley Wickham Supplemental: R for Data Science by Garrett Grolemund and Hadley Wickham Supplemental: The R Inferno by Patrick Burns Supplemental: R Programming for Data Science by Roger D. Peng Supplemental: Seamless R and C++ integration with Rcpp by Dirk Eddelbuettel Supplemental: Engineering Production-Grade Shiny Apps by Colin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard  We regrouped more references by category in the resources page.\nSoftware All the software we will be using are free for acamedic activities. The course will use and present the R statistical computing language as well as different parts of C++ through Rcpp. The integrated developer environment that we will use to explore R is RStudio IDE made by RStudio Inc. See https://blog.rstudio.com/2020/08/17/r-and-rstudio-the-interoperability-environment-for-data-analytics for why it would be interesting as data scientist to use R/RStudio.\n"
},
{
	"uri": "https://ptds.samorso.ch/project/",
	"title": "Project",
	"tags": [],
	"description": "",
	"content": "Project Project represents 30 points, so 50% of the final grade. Discover more about the project.\n"
},
{
	"uri": "https://ptds.samorso.ch/group/",
	"title": "Groups",
	"tags": [],
	"description": "",
	"content": "Discover with whom you\u0026rsquo;re going to work with\n"
},
{
	"uri": "https://ptds.samorso.ch/syllabus/final/",
	"title": "Convinced?",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ptds.samorso.ch/resources/",
	"title": "Resources",
	"tags": [],
	"description": "",
	"content": "Resources Getting started with R and Rstudio The CRAN website CRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of R and its documentation.\nAn Introduction to R This official and up-to-date tutorial, gives an introduction to the language and how to use R for doing statistical analysis and graphics.\nRStudio RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management.\nRstudio cheat sheets A trove of cheat sheets below to make it easy to learn about and use some of R\u0026rsquo;s most useful packages.\nR packages for data science The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\nOnline learning Coding club\u0026rsquo;s tutorials  Our mission is to create a fun and supportive environment where we develop programming and statistics skills together, using R.\nWe want to replace statistics anxiety and code fear with inspiration and motivation to learn, and here we will share our experience.\n Datacamp\u0026rsquo;s free R tutorial and Try R by Code School Both sites provide interactive lessons that will get you writing real code in minutes. They are a great place to make mistakes and test out new skills. You are told immediately when you go wrong and given a chance to fix your code.\nWriting functions in R This course will teach you the fundamentals of writing functions in R so that, among other things, you can make your code more readable, avoid coding errors, and automate repetitive tasks.\nIntroduction to the tidyverse This is an introduction to the dplyr and ggplot2 packages through exploration and visualization of country data over time. This is a suitable course for people who have no or limited experience in R and are interested in learning to perform data analysis.\nData visualisation with ggplot2 Covers the basics of ggplot2. Followed by part 2 which covers more advanced topics.\nExploratory data analysis in R: a case study This course brings ggplot2 and dplyr into action in an in-depth analysis of United Nations voting data. The course also introduces broom for tidying model output and the tidyr package for wrangling data into an explorable shape.\nBooks Advanced R  The book is designed primarily for R users who want to improve their programming skills and understanding of the language. It should also be useful for programmers coming to R from other languages, as it explains some of R’s quirks and shows how some parts that seem horrible do have a positive side. Hadley Wickham  R for Data Science  This book will teach you how to do data science with R: You\u0026rsquo;ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Garrett Grolemund and Hadley Wickham  Misc Easy web applications in R Shiny is an open source R package that provides an elegant and powerful web framework for building web applications using R. Shiny helps you turn your analyses into interactive web applications without requiring HTML, CSS, or JavaScript knowledge.\nRcpp for Seamless R and C++ Integration The Rcpp package has become the most widely used language extension for R, the powerful environment and language for computing with data. As of May 2017, 1026 packages on CRAN and a further 91 on BioConductor deploy Rcpp to extend R, to accelerate computations and to connect to other C++ projects.\n"
},
{
	"uri": "https://ptds.samorso.ch/",
	"title": "Programming tools in data science",
	"tags": [],
	"description": "",
	"content": "Programming tools in data science The objective of the website is to provide a support for Programming tools in data science given at the Faculty of Business and Economics (HEC Lausanne) of the University of Lausanne in Fall 2021. This course is intended to provide an introduction to programming using the R language. It will also provide students with notions of data management, data manipulation and data analysis as well as of reproducible research, result-sharing and version control (using GitHub). At the end of the class, students should be able to construct their own R package, make it available on GitHub, document it using literate programming and render it visible by making a website.\nThis class is based on the textbook: \u0026ldquo;An Introduction to Statistical Programming Methods with R\u0026rdquo; , which is available here: http://r.smac-group.com. This document is under development and it is therefore preferable to always access the text online to be sure you are using the most up-to-date version.\nLast information Find group composition here. Please, do the following:\n check that your name is there (otherwise, fill this form) check that there is no major issue with your group composition (otherwise contact me in on Slack ASAP) inform me if you, or another person in the group, don\u0026rsquo;t intend to follow this class so we can correct the group composition  Please note the following\n Lecture of the 11th of October is on Zoom (practical in the room). Checkout the lectures schedule for more details. The lectures and practicals can all be followed using the following unique zoom link: https://unil.zoom.us/j/93540191281?pwd=NzBvTWxYaTFqbEM1SUR5K2RLbiszQT09.  "
},
{
	"uri": "https://ptds.samorso.ch/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ptds.samorso.ch/group/groups/",
	"title": "Composition",
	"tags": [],
	"description": "",
	"content": "Here is the group composition :\nGroup 1  Aëllya Monney Rémy Tombola Laurène Hsieh Visesa Jain Corinne Schönholzer  Group 2  Matteo Gross Alessia Di Pietro Martina Celic Ana Gabriela Garcia Laura Lo Priore  Group 3  Ismail Sarah Abdulghafor Nada Lugon Waren Beijer Enzo Labinot Ismaili  Group 4  Daniel Szenes Ozgur Aydemir Francesco Darino Sophie La Gennusa Louis del Perugia  Group 5  Marie Bellier Rodrigues Telo Ramos Vania Renger Xavier Finini Massimo Likoska Meri  Group 6  Colin Steffe Daniel Welz Guillaume Bilocq Jasmine Mawjee Virany Kho  "
},
{
	"uri": "https://ptds.samorso.ch/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]